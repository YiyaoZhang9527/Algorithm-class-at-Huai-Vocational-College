{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7d8032ef-413a-42bf-911f-816d7fa26d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "数据洗牌: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1775.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-12-24 18:29:24.558895 - [INFO] - 训练数据中,正例有【169】个占比【0.37142857142857144】\n",
      "            ，负例有【286】个占比【0.6285714285714286】\n",
      "            ，alpha值为【0.6285714285714286】，\u001b[0m\n",
      "\u001b[0;34m2023-12-24 18:29:24.558980 - [INFO] - 测试数据中,正例有【43】个占比【0.37719298245614036】\n",
      "            ，负例有【71】个占比【0.6228070175438597】\n",
      "            ，alpha值为【0.6228070175438597】，\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559045 - [PASS] - 已准备优化的第1个参数,名称:loss,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{loss}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{deviance}\n",
      "6   Literal{exponential}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559073 - [PASS] - 已准备优化的第2个参数,名称:learning_rate,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{learning_rate}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559097 - [PASS] - 已准备优化的第3个参数,名称:n_estimators,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{n_estimators}\n",
      "3     quniform\n",
      "4       Literal{10}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559119 - [PASS] - 已准备优化的第4个参数,名称:subsample,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{subsample}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559144 - [PASS] - 已准备优化的第5个参数,名称:criterion,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{criterion}\n",
      "3     randint\n",
      "4       Literal{3}\n",
      "5   Literal{friedman_mse}\n",
      "6   Literal{squared_error}\n",
      "7   Literal{absolute_error}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559166 - [PASS] - 已准备优化的第6个参数,名称:min_samples_leaf,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_samples_leaf}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{0.5}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559187 - [PASS] - 已准备优化的第7个参数,名称:min_samples_split,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_samples_split}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559207 - [PASS] - 已准备优化的第8个参数,名称:min_weight_fraction_leaf,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_weight_fraction_leaf}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{0.5}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559228 - [PASS] - 已准备优化的第9个参数,名称:max_depth,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{max_depth}\n",
      "3     quniform\n",
      "4       Literal{1}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559246 - [PASS] - 已准备优化的第10个参数,名称:min_impurity_decrease,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_impurity_decrease}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559263 - [PASS] - 已准备优化的第11个参数,名称:random_state,类型:0 hyperopt_param\n",
      "1   Literal{random_state}\n",
      "2   randint\n",
      "3     Literal{100}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559287 - [PASS] - 已准备优化的第12个参数,名称:max_features,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{max_features}\n",
      "3     randint\n",
      "4       Literal{4}\n",
      "5   Literal{auto}\n",
      "6   Literal{sqrt}\n",
      "7   Literal{log2}\n",
      "8   Literal{None}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559309 - [PASS] - 已准备优化的第13个参数,名称:max_leaf_nodes,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{max_leaf_nodes}\n",
      "3     quniform\n",
      "4       Literal{2}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:29:24.559352 - [PASS] - 已准备优化的第14个参数,名称:warm_start,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{warm_start}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{True}\n",
      "6   Literal{False}\u001b[0m\n",
      "  0%|                                                                                                                                                                                                                                     | 0/1000 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████████████████▏                                                                                                                                                                   | 238/1000 [01:46<05:41,  2.23trial/s, best loss: -1.0]\n",
      "\n",
      " \n",
      " best params:  {'criterion': 0, 'learning_rate': 0.23265593628618167, 'loss': 1, 'max_depth': 625.0, 'max_features': 3, 'max_leaf_nodes': 885.0, 'min_impurity_decrease': 0.9137615753951835, 'min_samples_leaf': 0.11266315666906594, 'min_samples_split': 0.30033118853347274, 'min_weight_fraction_leaf': 0.23734129000876486, 'n_estimators': 119.0, 'random_state': 58, 'subsample': 0.863391305855304, 'warm_start': 1} \n",
      "\n",
      "\u001b[0;32m2023-12-24 18:31:11.384723 - [PASS] - 解析参数得到结果:{'loss': 'exponential', 'learning_rate': 0.23265593628618167, 'n_estimators': 119, 'subsample': 0.863391305855304, 'criterion': 'friedman_mse', 'min_samples_leaf': 0.11266315666906594, 'min_samples_split': 0.30033118853347274, 'min_weight_fraction_leaf': 0.23734129000876486, 'max_depth': 625, 'min_impurity_decrease': 0.9137615753951835, 'random_state': 58, 'max_features': None, 'max_leaf_nodes': 885, 'warm_start': False}\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.518897 - [SUCCESS] - 模型的评估报告1：\n",
      ",              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        71\n",
      "         1.0       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.519095 - [SUCCESS] - 模型的评估报告2：\n",
      ",{'混淆矩阵': matrix([[43,  0],\n",
      "        [ 0, 71]]), 'ACC正确率|accuracy': 1.0, '精确率|precision': 1.0, '召回率|recall｜真阳率｜命中率': 1.0, '误报率|false alarm｜假阳率｜虚警率｜误检率': 0.0, '漏报率|miss rate|也称为漏警率|漏检率': 0.0, '特异度|specificity': 1.0, 'F1-score:': 1.0, '真实正样本数': 43, '真实负样本数': 71}\n",
      "\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521199 - [SUCCESS] - 测试pr_auc值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521221 - [SUCCESS] - 测试roc_auc值为:1.0,权重为0.5\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521233 - [SUCCESS] - 测试accuracy值为:1.0,权重为0.5\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521242 - [SUCCESS] - 测试precision值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521251 - [SUCCESS] - 测试recall值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521259 - [SUCCESS] - 测试false_alarm值为:0.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521267 - [SUCCESS] - 测试miss_rate值为:0.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521275 - [SUCCESS] - 测试specificity值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521283 - [SUCCESS] - 测试f1score值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:31:11.521303 - [SUCCESS] - 测试优化参数的:【all】得分为:【1.0】,优化过程中的最高分为:【1.0】\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "system = platform.system()\n",
    "if system == \"Linux\":\n",
    "    plt.rcParams['font.sans-serif'] = [\"AR PL UKai CN\"] #[\"Noto Sans CJK JP\"]\n",
    "elif system == \"Darwin\":\n",
    "    plt.rcParams['font.sans-serif'] = [\"Kaiti SC\"]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from MyLogColor import  log,LogLevel\n",
    "import time\n",
    "import datetime\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from OptMetrics import MyMetric\n",
    "\n",
    "\n",
    "class BayesOptGBDT(MyMetric):\n",
    "    \n",
    "    def __init__(self,x,y\n",
    "                 ,Folds=6 #如果采用分层k折交叉验证的时候则写出分多少折\n",
    "                 ,TEST_SPLIT=0.2 #测试集的比例\n",
    "                 ,EARLY_STOP_BAYES =100 #当参数优化多少次没有进步的时候就停止搜索\n",
    "                 ,NUM_EVALS=600 #最大优化参数的搜索次数\n",
    "                 ,MAX_SHUFFLE=100 #数据洗牌的次数\n",
    "                 ,x_train=[], x_val=[], y_train=[], y_val=[]\n",
    "                 ,metrics_class = \"pr-auc\" #\"[pr-auc],[roc-auc],[f1-score],[recall],[precision],[accuracy],[roc-auc-recall],[roc-auc-accuracy]\"\n",
    "                 # all=[pr_auc,roc_auc,accuracy,precision,recall,false_alarm,miss_rate,specificity,f1score]\n",
    "                 ,metrics_weight = [0.5,0.5]\n",
    "                 ,min_recall = 0.5 #召回率的最小值\n",
    "                 ,cost_wight = 0.1 #对召回率不满足的情况下权重值的惩罚值\n",
    "                 ,StratifiedKFoldShuffle=True\n",
    "                #  ,is_verbose = False # 是否查看详细信息\n",
    "                ):\n",
    "        self.Folds = Folds\n",
    "        self.TEST_SPLIT =TEST_SPLIT\n",
    "        self.EARLY_STOP_BAYES = EARLY_STOP_BAYES\n",
    "        self.NUM_EVALS = NUM_EVALS\n",
    "        self.MAX_SHUFFLE = MAX_SHUFFLE\n",
    "        self.metrics_class = metrics_class\n",
    "        self.metrics_weight = np.array(metrics_weight)\n",
    "        self.metrics_weight = self.metrics_weight/self.metrics_weight.sum()\n",
    "        self.min_recall = min_recall\n",
    "        self.cost_wight = cost_wight\n",
    "        self.StratifiedKFoldShuffle = StratifiedKFoldShuffle\n",
    "        \n",
    "        self.Bayes_start_time = None\n",
    "        self.NOW_FUC_RUN_ITER = 0\n",
    "        self.Trials = None\n",
    "        self.bayes_opt_parser = None\n",
    "        self.PARAMS_BEST = None\n",
    "        self.historical_metrics = np.zeros(self.NUM_EVALS)\n",
    "        self.historical_params = {}\n",
    "        \n",
    "        self.all_metrice_names = ['pr_auc',\n",
    "                            'roc_auc',\n",
    "                            'accuracy',\n",
    "                            'precision',\n",
    "                            'recall',\n",
    "                            'false_alarm',\n",
    "                            'miss_rate',\n",
    "                            'specificity',\n",
    "                            'f1score']\n",
    "        \n",
    "        self.losss = [ 'deviance', 'exponential']\n",
    "        self.criterions = ['friedman_mse', 'squared_error', 'absolute_error']\n",
    "        # self.n_features = x.shape[-1]\n",
    "        self.Max_features = ['auto', 'sqrt', 'log2',None ]#+list(np.arange(1,x.shape[-1],1))\n",
    "                        # ,hp.randint(\"max_features_int\",0,x_train.shape[-1])\n",
    "                        # ,hp.uniform(\"max_features_float\",0,1)]\n",
    "        self.warm_starts = [True,False]\n",
    "        self.param_grid_hp = {\n",
    "            \"loss\":hp.choice(\"loss\",self.losss)\n",
    "            ,\"learning_rate\":hp.uniform(\"learning_rate\",0,1)\n",
    "            ,'n_estimators': hp.quniform(\"n_estimators\",10,1000,1)\n",
    "            ,'subsample':hp.uniform(\"subsample\",0,1)\n",
    "            ,\"criterion\":hp.choice(\"criterion\",self.criterions)\n",
    "            ,\"min_samples_leaf\":hp.uniform(\"min_samples_leaf\",0,0.5)\n",
    "            ,\"min_samples_split\":hp.uniform(\"min_samples_split\",0,1)\n",
    "            ,\"min_weight_fraction_leaf\":hp.uniform(\"min_weight_fraction_leaf\",0,0.5)\n",
    "            ,\"max_depth\":hp.quniform(\"max_depth\",1,1000,1)\n",
    "            ,\"min_impurity_decrease\":hp.uniform(\"min_impurity_decrease\",0,1)\n",
    "            # ,\"min_impurity_split\":hp.uniform(\"min_impurity_split\",0,1)\n",
    "            ,\"random_state\":hp.randint(\"random_state\",100)\n",
    "            ,\"max_features\":hp.choice(\"max_features\",self.Max_features)\n",
    "            ,\"max_leaf_nodes\":hp.quniform(\"max_leaf_nodes\",2,1000,1)\n",
    "            ,\"warm_start\":hp.choice(\"warm_start\",self.warm_starts)\n",
    "        }\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.m,self.n = x.shape\n",
    "        self.y = np.array(y,dtype=int)\n",
    "        \n",
    "        \n",
    "        if len(x_train) and len(x_val) and len(y_train) and len(y_val):\n",
    "            self.x_train, self.x_val, self.y_train, self.y_val = x_train,x_val,y_train,y_val\n",
    "        else:\n",
    "            if self.MAX_SHUFFLE > 0:\n",
    "                self.shuffle_x,self.shuffle_y = self.shuffle_data(x,y)\n",
    "                self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.shuffle_x, self.shuffle_y, test_size=self.TEST_SPLIT, random_state = 42)\n",
    "            else:\n",
    "                self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(x, y, test_size=self.TEST_SPLIT, random_state = 42)\n",
    "        self.train_positive = (self.y_train==1).sum()\n",
    "        self.train_negative = (self.y_train==0).sum()\n",
    "        self.train_y_counter = self.y_train.size\n",
    "        self.alpha = self.train_negative/self.train_y_counter\n",
    "\n",
    "        log(f\"\"\"训练数据中,正例有【{self.train_positive}】个占比【{self.train_positive/self.train_y_counter}】\n",
    "            ，负例有【{self.train_negative}】个占比【{self.train_negative/self.train_y_counter}】\n",
    "            ，alpha值为【{self.alpha}】，\"\"\",LogLevel.INFO)\n",
    "        \n",
    "        self.test_positive = (self.y_val==1).sum()\n",
    "        self.test_negative = (self.y_val==0).sum()\n",
    "        self.test_y_counter = self.y_val.size\n",
    "\n",
    "        log(f\"\"\"测试数据中,正例有【{self.test_positive}】个占比【{self.test_positive/self.test_y_counter }】\n",
    "            ，负例有【{self.test_negative}】个占比【{self.test_negative/self.test_y_counter }】\n",
    "            ，alpha值为【{self.test_negative/self.test_y_counter}】，\"\"\",LogLevel.INFO)\n",
    "\n",
    "\n",
    "    def shuffle_data(self,x,y):\n",
    "        \"\"\"\n",
    "        数据洗牌\n",
    "        \"\"\"\n",
    "        xy = np.c_[x,y]\n",
    "        for i in tqdm(range(self.MAX_SHUFFLE),desc=\"数据洗牌\"):\n",
    "            np.random.shuffle(xy)\n",
    "        x,y = xy[:,0:self.n],xy[:,self.n:self.n+1]\n",
    "        y = np.ravel(y)\n",
    "        return x,y\n",
    "    \n",
    "    def hyperopt_objective(self,params):\n",
    "        \n",
    "        func_start = time.time()\n",
    "        # log(f\"本次参数:{params}\",LogLevel.INFO) \n",
    "        try:\n",
    "            if isinstance(self.Folds,(int,float)) and self.Folds > 0:\n",
    "                # print(self.Folds)\n",
    "                # self.StratifiedKFoldShuffle\n",
    "                strkf = StratifiedKFold(n_splits=self.Folds, shuffle=self.StratifiedKFoldShuffle)\n",
    "                '''\n",
    "                n_splits=6（默认5）：将数据集分成6个互斥子集，每次用5个子集数据作为训练集，1个子集为测试集，得到6个结果\n",
    "\n",
    "                shuffle=True（默认False）：每次划分前数据重新洗牌，每次的运行结果不同；shuffle=False：每次运行结果相同，相当于random_state=整数\n",
    "                random_state=1（默认None）：随机数设置为1，使得每次运行的结果一致\n",
    "                '''\n",
    "                # roc_aucs = np.zeros(self.Folds)\n",
    "                metrics_ = np.zeros(self.Folds)\n",
    "                log(f\"k={self.Folds}折分层交叉验证\",LogLevel.PASS)\n",
    "                for i,index_ in enumerate(strkf.split(self.x,self.y)):\n",
    "                    train_index,test_index = index_\n",
    "                    # print(train_index,test_index)\n",
    "                    X_train_KFold, X_test_KFold = self.x[train_index],self.x[test_index]\n",
    "                    y_train_KFold, y_test_KFold = self.y[train_index],self.y[test_index]\n",
    "                    gbdtc = GradientBoostingClassifier(\n",
    "                            loss = params[\"loss\"]\n",
    "                            ,learning_rate = params[\"learning_rate\"]\n",
    "                            ,n_estimators= int(params[\"n_estimators\"])\n",
    "                            ,subsample = params[\"subsample\"]\n",
    "                            ,criterion = params[\"criterion\"]\n",
    "                            ,min_samples_leaf = params[\"min_samples_leaf\"]\n",
    "                            ,min_samples_split = params[\"min_samples_split\"]\n",
    "                            ,min_weight_fraction_leaf = params[\"min_weight_fraction_leaf\"]\n",
    "                            ,max_depth = int(params[\"max_depth\"])\n",
    "                            ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
    "                            # ,min_impurity_split = params[\"min_impurity_split\"]\n",
    "                            ,random_state = params[\"random_state\"]\n",
    "                            ,max_features = params[\"max_features\"]\n",
    "                            ,max_leaf_nodes = int(params[\"max_leaf_nodes\"])\n",
    "                            ,warm_start = params[\"warm_start\"]\n",
    "                        )\n",
    "                    gbdtc = gbdtc.fit(X_train_KFold, y_train_KFold)\n",
    "                    gbdtc_proba = gbdtc.predict_proba(X_test_KFold)[:,1]\n",
    "                    gbdtc_pred = gbdtc.predict(X_test_KFold)\n",
    "                    \n",
    "                    if self.metrics_class == \"pr-auc\":\n",
    "                        metrics_[i] = self.PR_AUC(y_test_KFold, gbdtc_proba,gbdtc_pred)\n",
    "                    elif self.metrics_class == \"roc-auc\":\n",
    "                        metrics_[i] = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                    elif self.metrics_class == \"f1-score\":\n",
    "                        metrics_[i] = f1_score(y_test_KFold,gbdtc_pred) \n",
    "                    elif self.metrics_class == \"recall\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "                    elif self.metrics_class == \"precision\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"精确率|precision\"] \n",
    "                    elif self.metrics_class == \"accuracy\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                    elif self.metrics_class == \"roc-auc-recall\":\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        recall = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        metrics_[i] = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[-1]\n",
    "                    elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        recall = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        accuracy = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                        metrics_[i] = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1] \n",
    "                    if self.metrics_class == \"all\":\n",
    "                        TPRN = self.TPRN_Score(y_test_KFold,gbdtc_pred)\n",
    "                        pr_auc = self.PR_AUC(y_test_KFold, gbdtc_proba,gbdtc_pred)\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "                        precision = TPRN['精确率|precision']\n",
    "                        recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "                        miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "                        specificity = TPRN['特异度|specificity']\n",
    "                        f1score = f1_score(y_test_KFold,gbdtc_pred) \n",
    "                        \n",
    "                        metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,-false_alarm,-miss_rate,specificity,f1score])\n",
    "                        \n",
    "                        metrics_values = np.nan_to_num(metrics_values,0)\n",
    "                        if recall > self.min_recall:\n",
    "                            metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "                        else:\n",
    "                            metrics_weight = np.nan_to_num(self.metrics_weight,0)*self.cost_wight\n",
    "                        metrics_[i] = metrics_values.dot(metrics_weight)                    \n",
    "                # roc_auc  = roc_aucs.mean()\n",
    "                metrics_value = metrics_.mean()\n",
    "                    \n",
    "            else: \n",
    "                gbdtc = GradientBoostingClassifier(\n",
    "                    loss = params[\"loss\"]\n",
    "                    ,learning_rate = params[\"learning_rate\"]\n",
    "                    ,n_estimators= int(params[\"n_estimators\"])\n",
    "                    ,subsample = params[\"subsample\"]\n",
    "                    ,criterion = params[\"criterion\"]\n",
    "                    ,min_samples_leaf = params[\"min_samples_leaf\"]\n",
    "                    ,min_samples_split = params[\"min_samples_split\"]\n",
    "                    ,min_weight_fraction_leaf = params[\"min_weight_fraction_leaf\"]\n",
    "                    ,max_depth = int(params[\"max_depth\"])\n",
    "                    ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
    "                    # ,min_impurity_split = params[\"min_impurity_split\"]\n",
    "                    ,random_state = params[\"random_state\"]\n",
    "                    ,max_features = params[\"max_features\"]\n",
    "                    ,max_leaf_nodes = int(params[\"max_leaf_nodes\"])\n",
    "                    ,warm_start = params[\"warm_start\"]\n",
    "                )\n",
    "                gbdtc =gbdtc.fit(self.x_train, self.y_train)\n",
    "                gbdtc_proba = gbdtc.predict_proba(self.x_val)[:,1]\n",
    "                gbdtc_pred = gbdtc.predict(self.x_val)\n",
    "                if self.metrics_class == \"pr-auc\":\n",
    "                    metrics_value = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "                elif self.metrics_class == \"roc-auc\":\n",
    "                    metrics_value = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                elif self.metrics_class == \"f1-score\":\n",
    "                    metrics_value = f1_score(self.y_val,gbdtc_pred)\n",
    "                elif self.metrics_class == \"recall\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "                elif self.metrics_class == \"precision\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"精确率|precision\"] \n",
    "                elif self.metrics_class == \"accuracy\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                elif self.metrics_class == \"roc-auc-recall\":\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    metrics_value = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[-1]\n",
    "                elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    accuracy = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                    metrics_value = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1]                      \n",
    "                if self.metrics_class == \"all\":\n",
    "                    TPRN = self.TPRN_Score(self.y_val, gbdtc_pred)\n",
    "                    pr_auc = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "                    precision = TPRN['精确率|precision']\n",
    "                    recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "                    miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "                    specificity = TPRN['特异度|specificity']\n",
    "                    f1score = f1_score(self.y_val,gbdtc_pred) \n",
    "                    metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,-false_alarm,-miss_rate,specificity,f1score])\n",
    "                    metrics_values = np.nan_to_num(metrics_values,0)\n",
    "                    if recall > self.min_recall:\n",
    "                        metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "                    else:\n",
    "                        metrics_weight = np.nan_to_num(self.metrics_weight,0)*self.cost_wight\n",
    "                    metrics_value = metrics_values.dot(metrics_weight)\n",
    "        except Exception as e:\n",
    "            log(f\"{str(e)},{params['max_features']}\",LogLevel.ERROR)\n",
    "            metrics_value = self.historical_metrics.mean()   \n",
    "        # metrics_value = MyMetric.PR_AUC(self.y_val,gbdtc_proba,gbdtc_pred)\n",
    "        \n",
    "        func_end = time.time()\n",
    "        # global NOW_FUC_RUN_ITER\n",
    "        self.NOW_FUC_RUN_ITER += 1\n",
    "        self.historical_params.update({self.NOW_FUC_RUN_ITER-1:params})\n",
    "        self.historical_metrics[self.NOW_FUC_RUN_ITER-1]=metrics_value\n",
    "        \n",
    "        # log(f\"\"\"本次迭代{self.metrics_class}分数为:[{metrics_value}],\n",
    "        # 用时:[{func_end-func_start}]秒,\n",
    "        # 当前优化第:[{self.NOW_FUC_RUN_ITER}]次,\n",
    "        # 已运行:[{self.NOW_FUC_RUN_ITER}]次，\n",
    "        # 用时总计:[{datetime.timedelta(seconds=(func_end-self.Bayes_start_time))}]秒,\n",
    "        # \"\"\",LogLevel.PASS)\n",
    "        return -metrics_value\n",
    "    \n",
    "    def param_hyperopt(self,max_evals=100):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #保存迭代过程\n",
    "        trials = Trials()\n",
    "\n",
    "        #设置提前停止\n",
    "        ## 如果损失没有增加，将在 X 次迭代后停止的停止函数\n",
    "        early_stop_fn = no_progress_loss(self.EARLY_STOP_BAYES)\n",
    "\n",
    "        #定义代理模型\n",
    "        #algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)\n",
    "        # global hyperopt_params\n",
    "        # hyperopt_params = self.param_grid_hp\n",
    "        params_best = fmin(self.hyperopt_objective #目标函数\n",
    "                        , space = self.param_grid_hp #参数空间\n",
    "                        , algo = tpe.suggest #代理模型\n",
    "                        #, algo = algo\n",
    "                        , max_evals = max_evals #允许的迭代次数\n",
    "                        , verbose=True\n",
    "                        , trials = trials\n",
    "                        , early_stop_fn = early_stop_fn\n",
    "                        \n",
    "                        )\n",
    "\n",
    "        #打印最优参数，fmin会自动打印最佳分数\n",
    "        print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "            \"\\n\")\n",
    "        return params_best, trials\n",
    "    \n",
    "    def parsing_bayes_params_for_GBDT(self,params):\n",
    "        max_features_params = self.Max_features[int(params[\"max_features\"])]\n",
    "        \n",
    "        return {\"loss\":self.losss[int(params[\"loss\"])]\n",
    "            ,\"learning_rate\":params[\"learning_rate\"]\n",
    "            ,\"n_estimators\": int(params[\"n_estimators\"])\n",
    "            ,\"subsample\": params[\"subsample\"]\n",
    "            ,\"criterion\" : self.criterions[int(params[\"criterion\"])]\n",
    "            ,\"min_samples_leaf\" : params[\"min_samples_leaf\"]\n",
    "            ,\"min_samples_split\" :  params[\"min_samples_split\"]\n",
    "            ,\"min_weight_fraction_leaf\" : params[\"min_weight_fraction_leaf\"]\n",
    "            ,\"max_depth\" : int(params[\"max_depth\"])\n",
    "            ,\"min_impurity_decrease\": params[\"min_impurity_decrease\"]\n",
    "            # ,min_impurity_split = params[\"min_impurity_split\"]\n",
    "            ,\"random_state\" : params[\"random_state\"]\n",
    "            ,\"max_features\": max_features_params\n",
    "            ,\"max_leaf_nodes\": int(params[\"max_leaf_nodes\"])\n",
    "            ,\"warm_start\" : self.warm_starts[params[\"warm_start\"]]\n",
    "            }\n",
    "        \n",
    "    def run(self):\n",
    "        t = 0\n",
    "        for params_name,obj in self.param_grid_hp.items():\n",
    "            t += 1\n",
    "            log(f\"已准备优化的第{t}个参数,名称:{params_name},类型:{obj}\",LogLevel.PASS)\n",
    "\n",
    "        self.Bayes_start_time = time.time()\n",
    "        self.NOW_FUC_RUN_ITER = 0\n",
    "        self.PARAMS_BEST, self.Trials = self.param_hyperopt(self.NUM_EVALS)\n",
    "        self.bayes_opt_parser = self.parsing_bayes_params_for_GBDT(self.PARAMS_BEST)\n",
    "        log(f\"解析参数得到结果:{self.bayes_opt_parser}\",LogLevel.PASS)\n",
    "        \n",
    "    def test_params(self):\n",
    "        params = self.bayes_opt_parser\n",
    "        # if int(params[\"max_features\"]) - params[\"max_features\"]== 0:\n",
    "        # max_features_params = self.Max_features[int(params[\"max_features\"])]\n",
    "        # else:\n",
    "        #     max_features_params = params[\"max_features\"]\n",
    "            \n",
    "        gbdtc = GradientBoostingClassifier(\n",
    "            loss = params[\"loss\"]\n",
    "            ,learning_rate = params[\"learning_rate\"]\n",
    "            ,n_estimators= params[\"n_estimators\"]\n",
    "            ,subsample = params[\"subsample\"]\n",
    "            ,criterion = params[\"criterion\"]\n",
    "            ,min_samples_leaf = params[\"min_samples_leaf\"]\n",
    "            ,min_samples_split = params[\"min_samples_split\"]\n",
    "            ,min_weight_fraction_leaf = params[\"min_weight_fraction_leaf\"]\n",
    "            ,max_depth = params[\"max_depth\"]\n",
    "            ,min_impurity_decrease = params[\"min_impurity_decrease\"]\n",
    "            # ,min_impurity_split = params[\"min_impurity_split\"]\n",
    "            ,random_state = params[\"random_state\"]\n",
    "            ,max_features = params[\"max_features\"]\n",
    "            ,max_leaf_nodes = params[\"max_leaf_nodes\"]\n",
    "            ,warm_start = params[\"warm_start\"]\n",
    "        )\n",
    "        gbdtc =gbdtc.fit(self.x_train, self.y_train)\n",
    "        gbdtc_proba = gbdtc.predict_proba(self.x_val)[:,1]\n",
    "        gbdtc_pred = gbdtc.predict(self.x_val)\n",
    "        # metric = MyMetric.PR_AUC(self.y_val,gbdtc_proba,gbdtc_pred)\n",
    "        log(f'模型的评估报告1：\\n,{classification_report(self.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)\n",
    "        log(f'模型的评估报告2：\\n,{self.TPRN_Score(self.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)\n",
    "        \n",
    "        # self.plot_roc(self.y_val, gbdtc_proba[:,1])\n",
    "        if self.metrics_class == \"pr-auc\":\n",
    "            metrics = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "        elif self.metrics_class == \"roc-auc\":\n",
    "            metrics = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "        elif self.metrics_class == \"f1-score\":\n",
    "            metrics = f1_score(self.y_val,gbdtc_pred)\n",
    "        elif self.metrics_class == \"recall\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "        elif self.metrics_class == \"precision\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"精确率|precision\"] \n",
    "        elif self.metrics_class == \"accuracy\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "        elif self.metrics_class == \"roc-auc-recall\":\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            metrics = roc_auc*self.metrics_weight[0]*recall*self.metrics_weight[-1]\n",
    "        elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            accuracy = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "            metrics = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1]                      \n",
    "        if self.metrics_class == \"all\":\n",
    "            TPRN = self.TPRN_Score(self.y_val, gbdtc_pred)\n",
    "            pr_auc = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "            precision = TPRN['精确率|precision']\n",
    "            recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "            miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "            specificity = TPRN['特异度|specificity']\n",
    "            f1score = f1_score(self.y_val,gbdtc_pred) \n",
    "            metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,false_alarm,miss_rate,specificity,f1score])\n",
    "            #metrics_weight = np.array(self.metrics_weight)\n",
    "            metrics_values = np.nan_to_num(metrics_values,0)\n",
    "            metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "            for metrice_name,metrics_value,weight in zip(self.all_metrice_names,metrics_values,metrics_weight):\n",
    "                log(f'测试{metrice_name}值为:{metrics_value},权重为{weight}',LogLevel.SUCCESS)\n",
    "            metrics = metrics_values.dot(metrics_weight) \n",
    "        log(f'测试优化参数的:【{self.metrics_class}】得分为:【{metrics}】,优化过程中的最高分为:【{self.historical_metrics.max()}】',LogLevel.SUCCESS)\n",
    "        return metrics\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    from sklearn import datasets\n",
    "    cancer=datasets.load_breast_cancer()\n",
    "    x=cancer.data\n",
    "    y=cancer.target\n",
    "\n",
    "    def Rollover(x):\n",
    "        x = x.astype(bool)\n",
    "        x = ~x\n",
    "        x = x.astype(int)\n",
    "        return x\n",
    "    ####TODO:将少数变成正例\n",
    "    y = Rollover(y)\n",
    "    boG = BayesOptGBDT(x,y\n",
    "                       ,MAX_SHUFFLE=100\n",
    "                        ,Folds=0\n",
    "                        ,metrics_class=\"all\"\n",
    "                        #all=[1.pr_auc,2.roc_auc,3.accuracy,4.precision,5.recall,6.false_alarm,7.miss_rate,8.specificity,9.f1score]\n",
    "                        ,metrics_weight=[0,0.5,0.5,0,0,0,0,0,0]\n",
    "                        ,EARLY_STOP_BAYES=200\n",
    "                        ,NUM_EVALS=1000\n",
    "                        ,min_recall=0\n",
    "                        ,cost_wight=1\n",
    "                       )\n",
    "    boG.run()\n",
    "    boG.test_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f02220c2-f2e2-444d-aed1-87fea9906083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.argmin(boG.Trials.losses())\n",
    "# boG.Trials.trials[idx]['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b9541d4c-1a59-471b-ac26-f1e110e31476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d4bd7154-1666-41f3-8f5a-bc9587d29bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(boG.Trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "98f938f7-c6a4-4cfd-9b1e-e7fa7d263b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boG.PARAMS_BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "20ebb769-e47a-4005-9c28-4e5c185b8a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.23265593628618167,\n",
       " 'loss': 'exponential',\n",
       " 'max_depth': 625.0,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 885.0,\n",
       " 'min_impurity_decrease': 0.9137615753951835,\n",
       " 'min_samples_leaf': 0.11266315666906594,\n",
       " 'min_samples_split': 0.30033118853347274,\n",
       " 'min_weight_fraction_leaf': 0.23734129000876486,\n",
       " 'n_estimators': 119.0,\n",
       " 'random_state': 58,\n",
       " 'subsample': 0.863391305855304,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmin([-boG.historical_metrics])\n",
    "boG.historical_params[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "da868f0d-acac-46f4-a043-95dc8e7e7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol = {'loss': 'exponential', 'learning_rate': 0.23265593628618167, 'n_estimators': 119\n",
    "      , 'subsample': 0.863391305855304, 'criterion': 'friedman_mse'\n",
    "      , 'min_samples_leaf': 0.11266315666906594, 'min_samples_split': 0.30033118853347274\n",
    "      , 'min_weight_fraction_leaf': 0.23734129000876486, 'max_depth': 625, 'min_impurity_decrease': 0.9137615753951835\n",
    "      , 'random_state': 58, 'max_features': None, 'max_leaf_nodes': 885, 'warm_start': False}\n",
    "\n",
    "ol == boG.historical_params[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ca27136a-f4ad-4e95-b46e-b064881d75ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m2023-12-24 18:34:42.868609 - [SUCCESS] - 模型的评估报告1：\n",
      ",              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        71\n",
      "         1.0       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:34:42.868905 - [SUCCESS] - 模型的评估报告2：\n",
      ",{'混淆矩阵': matrix([[43,  0],\n",
      "        [ 0, 71]]), 'ACC正确率|accuracy': 1.0, '精确率|precision': 1.0, '召回率|recall｜真阳率｜命中率': 1.0, '误报率|false alarm｜假阳率｜虚警率｜误检率': 0.0, '漏报率|miss rate|也称为漏警率|漏检率': 0.0, '特异度|specificity': 1.0, 'F1-score:': 1.0, '真实正样本数': 43, '真实负样本数': 71}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gbdtc = GradientBoostingClassifier(**boG.bayes_opt_parser)\n",
    "gbdtc =gbdtc.fit(boG.x_train, boG.y_train)\n",
    "gbdtc_proba = gbdtc.predict_proba(boG.x_val)[:,1]\n",
    "gbdtc_pred = gbdtc.predict(boG.x_val)\n",
    "# metric = MyMetric.PR_AUC(self.y_val,gbdtc_proba,gbdtc_pred)\n",
    "log(f'模型的评估报告1：\\n,{classification_report(boG.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)\n",
    "log(f'模型的评估报告2：\\n,{boG.TPRN_Score(boG.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a2b1f-9c6f-4841-b085-6765e2d7aba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a9b4ab7-cb54-48ae-bcde-c66beb1ab402",
   "metadata": {},
   "outputs": [],
   "source": [
    "boG.bayes_opt_parser['max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01f8d393-618e-49f2-9c11-61b83d8c3844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(boG.bayes_opt_parser['max_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "95f3e1d9-6ba7-4bc7-8aa5-9b178d8d854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803270869607691"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import precision_recall_curve,auc,f1_score,roc_curve,auc\n",
    "cancer=datasets.load_breast_cancer()\n",
    "x=cancer.data\n",
    "y=cancer.target\n",
    "\n",
    "\n",
    "def Rollover(x):\n",
    "    x = x.astype(bool)\n",
    "    x = ~x\n",
    "    x = x.astype(int)\n",
    "    return x\n",
    "####TODO:将少数变成正例\n",
    "y = Rollover(y)\n",
    "\n",
    "def ROC_AUC(test_y, proba):\n",
    "    fpr,tpr,threshold = roc_curve(test_y, proba)\n",
    "    roc_auc_ = auc(fpr,tpr)\n",
    "    return roc_auc_\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42) \n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(train_x,train_y,)\n",
    "rfc_pred = rfc.predict(test_x)\n",
    "rfc_proba = rfc.predict_proba(test_x)[:,1]\n",
    "(ROC_AUC(test_y,rfc_proba)+sum(rfc_pred==test_y)/test_y.size)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8d71a-3504-4a5f-9a59-99b212c6a4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0e5e82d1-c383-406e-abe1-4e6ae3043859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "数据洗牌: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1908.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-12-24 18:17:29.489942 - [INFO] - 训练数据中,正例有【174】个占比【0.3824175824175824】\n",
      "            ，负例有【281】个占比【0.6175824175824176】\n",
      "            ，alpha值为【0.6175824175824176】，\u001b[0m\n",
      "\u001b[0;34m2023-12-24 18:17:29.490106 - [INFO] - 测试数据中,正例有【38】个占比【0.3333333333333333】\n",
      "            ，负例有【76】个占比【0.6666666666666666】\n",
      "            ，alpha值为【0.6666666666666666】，\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490154 - [PASS] - 已准备优化的第1个参数,名称:n_estimators,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{n_estimators}\n",
      "3     quniform\n",
      "4       Literal{10}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490181 - [PASS] - 已准备优化的第2个参数,名称:criterion,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{criterion}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{gini}\n",
      "6   Literal{entropy}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490211 - [PASS] - 已准备优化的第3个参数,名称:max_depth,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{max_depth}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{None}\n",
      "6   hyperopt_param\n",
      "7     Literal{max_depth_int}\n",
      "8     randint\n",
      "9       Literal{0}\n",
      "10       Literal{1000}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490235 - [PASS] - 已准备优化的第4个参数,名称:min_samples_split,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_samples_split}\n",
      "3     quniform\n",
      "4       Literal{2}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490257 - [PASS] - 已准备优化的第5个参数,名称:min_samples_leaf,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_samples_leaf}\n",
      "3     quniform\n",
      "4       Literal{1}\n",
      "5       Literal{1000}\n",
      "6       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490276 - [PASS] - 已准备优化的第6个参数,名称:min_weight_fraction_leaf,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_weight_fraction_leaf}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{0.5}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490301 - [PASS] - 已准备优化的第7个参数,名称:max_features,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{max_features}\n",
      "3     randint\n",
      "4       Literal{4}\n",
      "5   Literal{auto}\n",
      "6   Literal{sqrt}\n",
      "7   Literal{log2}\n",
      "8   Literal{None}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490332 - [PASS] - 已准备优化的第8个参数,名称:max_leaf_nodes,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{max_leaf_nodes}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{None}\n",
      "6   float\n",
      "7     hyperopt_param\n",
      "8       Literal{max_leaf_nodes_int}\n",
      "9       quniform\n",
      "10         Literal{1}\n",
      "11         Literal{1000}\n",
      "12         Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490351 - [PASS] - 已准备优化的第9个参数,名称:min_impurity_decrease,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{min_impurity_decrease}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490372 - [PASS] - 已准备优化的第10个参数,名称:bootstrap,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{bootstrap}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{True}\n",
      "6   Literal{False}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490391 - [PASS] - 已准备优化的第11个参数,名称:oob_score,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{oob_score}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{True}\n",
      "6   Literal{False}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490407 - [PASS] - 已准备优化的第12个参数,名称:random_state,类型:0 hyperopt_param\n",
      "1   Literal{random_state}\n",
      "2   randint\n",
      "3     Literal{100}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490427 - [PASS] - 已准备优化的第13个参数,名称:warm_start,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{warm_start}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{True}\n",
      "6   Literal{False}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490446 - [PASS] - 已准备优化的第14个参数,名称:class_weight,类型:0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{class_weight}\n",
      "3     randint\n",
      "4       Literal{2}\n",
      "5   Literal{None}\n",
      "6   Literal{balanced}\u001b[0m\n",
      "\u001b[0;32m2023-12-24 18:17:29.490465 - [PASS] - 已准备优化的第15个参数,名称:max_samples,类型:0 float\n",
      "1   hyperopt_param\n",
      "2     Literal{max_samples}\n",
      "3     uniform\n",
      "4       Literal{0}\n",
      "5       Literal{1}\u001b[0m\n",
      "  0%|                                                                                                                                                                                                                                     | 0/1000 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m2023-12-24 18:19:49.806773 - [ERROR] - max_leaf_nodes 1 must be either None or larger than 1\u001b[0m                                                                                                                                                                            \n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 845/1000 [08:44<01:36,  1.61trial/s, best loss: -0.9641271038528311]\n",
      "\n",
      " \n",
      " best params:  {'bootstrap': 1, 'class_weight': 0, 'criterion': 0, 'max_depth': 1, 'max_depth_int': 286, 'max_features': 0, 'max_leaf_nodes': 0, 'max_samples': 0.050605447156075296, 'min_impurity_decrease': 0.14211011160987627, 'min_samples_leaf': 106.0, 'min_samples_split': 416.0, 'min_weight_fraction_leaf': 0.28522148572414313, 'n_estimators': 526.0, 'oob_score': 0, 'random_state': 56, 'warm_start': 1} \n",
      "\n",
      "\u001b[0;32m2023-12-24 18:26:13.865009 - [PASS] - 解析参数得到结果:{'n_estimators': 526, 'criterion': 'gini', 'max_depth': 286, 'min_samples_split': 416, 'min_samples_leaf': 106, 'min_weight_fraction_leaf': 0.28522148572414313, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.14211011160987627, 'bootstrap': False, 'oob_score': False, 'random_state': 56, 'warm_start': False, 'class_weight': None, 'max_samples': None, 'n_jobs': -1}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "system = platform.system()\n",
    "if system == \"Linux\":\n",
    "    plt.rcParams['font.sans-serif'] = [\"AR PL UKai CN\"] #[\"Noto Sans CJK JP\"]\n",
    "elif system == \"Darwin\":\n",
    "    plt.rcParams['font.sans-serif'] = [\"Kaiti SC\"]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from MyLogColor import  log,LogLevel\n",
    "import time\n",
    "import datetime\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from OptMetrics import MyMetric\n",
    "\n",
    "\n",
    "class BayesOptRF(MyMetric):\n",
    "    \n",
    "    def __init__(self,x,y\n",
    "                 ,Folds=6 #如果采用分层k折交叉验证的时候则写出分多少折\n",
    "                 ,TEST_SPLIT=0.2 #测试集的比例\n",
    "                 ,EARLY_STOP_BAYES =100 #当参数优化多少次没有进步的时候就停止搜索\n",
    "                 ,NUM_EVALS=600 #最大优化参数的搜索次数\n",
    "                 ,MAX_SHUFFLE=100 #数据洗牌的次数\n",
    "                 ,x_train=[], x_val=[], y_train=[], y_val=[]\n",
    "                 ,metrics_class = \"pr-auc\" #\"[pr-auc],[roc-auc],[f1-score],[recall],[precision],[accuracy],[roc-auc-recall],[roc-auc-accuracy]\"\n",
    "                 # all=[pr_auc,roc_auc,accuracy,precision,recall,false_alarm,miss_rate,specificity,f1score]\n",
    "                 ,metrics_weight = [0.5,0.5]\n",
    "                 ,min_recall = 0.5 #召回率的最小值\n",
    "                 ,cost_wight = 0.1 #对召回率不满足的情况下权重值的惩罚值\n",
    "                 ,StratifiedKFoldShuffle=True\n",
    "                #  ,is_verbose = False # 是否查看详细信息\n",
    "                ):\n",
    "        self.Folds = Folds\n",
    "        self.TEST_SPLIT =TEST_SPLIT\n",
    "        self.EARLY_STOP_BAYES = EARLY_STOP_BAYES\n",
    "        self.NUM_EVALS = NUM_EVALS\n",
    "        self.MAX_SHUFFLE = MAX_SHUFFLE\n",
    "        self.metrics_class = metrics_class\n",
    "        self.metrics_weight = np.array(metrics_weight)\n",
    "        self.metrics_weight = self.metrics_weight/self.metrics_weight.sum()\n",
    "        self.min_recall = min_recall\n",
    "        self.cost_wight = cost_wight\n",
    "        self.StratifiedKFoldShuffle = StratifiedKFoldShuffle\n",
    "        \n",
    "        self.Bayes_start_time = None\n",
    "        self.NOW_FUC_RUN_ITER = 0\n",
    "        self.Trials = None\n",
    "        self.bayes_opt_parser = None\n",
    "        self.PARAMS_BEST = None\n",
    "        self.historical_metrics = np.zeros(self.NUM_EVALS)\n",
    "        self.historical_params = {}\n",
    "        \n",
    "        self.all_metrice_names = ['pr_auc',\n",
    "                            'roc_auc',\n",
    "                            'accuracy',\n",
    "                            'precision',\n",
    "                            'recall',\n",
    "                            'false_alarm',\n",
    "                            'miss_rate',\n",
    "                            'specificity',\n",
    "                            'f1score']\n",
    "        \n",
    "        \n",
    "        self.losss = [ 'deviance', 'exponential']\n",
    "        self.criterions = ['friedman_mse', 'squared_error', 'absolute_error']\n",
    "        self.Max_features = ['auto', 'sqrt', 'log2',None]#+list(np.arange(0,1,0.001))\n",
    "                        # ,hp.randint(\"max_features_int\",0,x_train.shape[-1])\n",
    "                        # ,hp.uniform(\"max_features_float\",0,1)]\n",
    "        self.criterions = [\"gini\", \"entropy\"]\n",
    "        self.max_depths = [None,hp.randint(\"max_depth_int\",0,1000)]\n",
    "        self.Max_features = ['auto', 'sqrt', 'log2',None]#,hp.quniform(\"max_features_int\",1,1000,1),hp.uniform(\"max_features_float\",1e-10,1)]\n",
    "        self.Max_leaf_nodes = [None,hp.quniform(\"max_leaf_nodes_int\",1,1000,1)]\n",
    "        self.bootstraps = [True,False]\n",
    "        self.oob_scores = [True,False]\n",
    "        self.warm_starts = [True,False]\n",
    "        self.class_weights = [None,'balanced']\n",
    "        self.param_grid_hp = {\n",
    "            \"n_estimators\":hp.quniform(\"n_estimators\",10,1000,1)\n",
    "            ,\"criterion\":hp.choice(\"criterion\",self.criterions)\n",
    "            ,\"max_depth\":hp.choice(\"max_depth\",self.max_depths)\n",
    "            ,\"min_samples_split\":hp.quniform(\"min_samples_split\",2,1000,1)\n",
    "            ,\"min_samples_leaf\":hp.quniform(\"min_samples_leaf\",1,1000,1)\n",
    "            ,\"min_weight_fraction_leaf\":hp.uniform(\"min_weight_fraction_leaf\",0,0.5)\n",
    "            ,\"max_features\":hp.choice(\"max_features\",self.Max_features)\n",
    "            ,\"max_leaf_nodes\":hp.choice(\"max_leaf_nodes\",self.Max_leaf_nodes)\n",
    "            ,\"min_impurity_decrease\":hp.uniform(\"min_impurity_decrease\",0,1)\n",
    "            ,\"bootstrap\":hp.choice(\"bootstrap\",self.bootstraps)\n",
    "            ,\"oob_score\":hp.choice(\"oob_score\",self.oob_scores)\n",
    "            ,\"random_state\":hp.randint(\"random_state\",100)\n",
    "            # ,\"verbose\":hp.quniform(\"verbose\",0,1000,1)\n",
    "            ,\"warm_start\":hp.choice(\"warm_start\",self.warm_starts)\n",
    "            ,\"class_weight\":hp.choice(\"class_weight\",self.class_weights)\n",
    "            ,\"max_samples\":hp.uniform(\"max_samples\",0,1)\n",
    "        }\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.m,self.n = x.shape\n",
    "        self.y = np.array(y,dtype=int)\n",
    "        \n",
    "        \n",
    "        if len(x_train) and len(x_val) and len(y_train) and len(y_val):\n",
    "            self.x_train, self.x_val, self.y_train, self.y_val = x_train,x_val,y_train,y_val\n",
    "        else:\n",
    "            if self.MAX_SHUFFLE > 0:\n",
    "                self.shuffle_x,self.shuffle_y = self.shuffle_data(x,y)\n",
    "                self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.shuffle_x, self.shuffle_y, test_size=self.TEST_SPLIT, random_state = 42)\n",
    "            else:\n",
    "                self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(x, y, test_size=self.TEST_SPLIT, random_state = 42)\n",
    "        self.train_positive = (self.y_train==1).sum()\n",
    "        self.train_negative = (self.y_train==0).sum()\n",
    "        self.train_y_counter = self.y_train.size\n",
    "        self.alpha = self.train_negative/self.train_y_counter\n",
    "\n",
    "        log(f\"\"\"训练数据中,正例有【{self.train_positive}】个占比【{self.train_positive/self.train_y_counter}】\n",
    "            ，负例有【{self.train_negative}】个占比【{self.train_negative/self.train_y_counter}】\n",
    "            ，alpha值为【{self.alpha}】，\"\"\",LogLevel.INFO)\n",
    "        \n",
    "        self.test_positive = (self.y_val==1).sum()\n",
    "        self.test_negative = (self.y_val==0).sum()\n",
    "        self.test_y_counter = self.y_val.size\n",
    "\n",
    "        log(f\"\"\"测试数据中,正例有【{self.test_positive}】个占比【{self.test_positive/self.test_y_counter }】\n",
    "            ，负例有【{self.test_negative}】个占比【{self.test_negative/self.test_y_counter }】\n",
    "            ，alpha值为【{self.test_negative/self.test_y_counter}】，\"\"\",LogLevel.INFO)\n",
    "\n",
    "\n",
    "    def shuffle_data(self,x,y):\n",
    "        \"\"\"\n",
    "        数据洗牌\n",
    "        \"\"\"\n",
    "        xy = np.c_[x,y]\n",
    "        for i in tqdm(range(self.MAX_SHUFFLE),desc=\"数据洗牌\"):\n",
    "            np.random.shuffle(xy)\n",
    "        x,y = xy[:,0:self.n],xy[:,self.n:self.n+1]\n",
    "        y = np.ravel(y)\n",
    "        return x,y\n",
    "    \n",
    "    def hyperopt_objective(self,hyperopt_params):\n",
    "        \n",
    "        func_start = time.time()\n",
    "        params = {\n",
    "            \"n_estimators\":int(hyperopt_params[\"n_estimators\"])\n",
    "            ,\"criterion\":hyperopt_params[\"criterion\"]\n",
    "            ,\"max_depth\":hyperopt_params[\"max_depth\"]\n",
    "            ,\"min_samples_split\":int(hyperopt_params[\"min_samples_split\"])\n",
    "            ,\"min_samples_leaf\":int(hyperopt_params[\"min_samples_leaf\"])\n",
    "            ,\"min_weight_fraction_leaf\":hyperopt_params[\"min_weight_fraction_leaf\"]\n",
    "            ,\"max_features\":hyperopt_params[\"max_features\"]\n",
    "            ,\"max_leaf_nodes\":type(hyperopt_params[\"max_leaf_nodes\"])==float and int(hyperopt_params[\"max_leaf_nodes\"]) or None\n",
    "            ,\"min_impurity_decrease\":hyperopt_params[\"min_impurity_decrease\"]\n",
    "            ,\"bootstrap\":hyperopt_params[\"bootstrap\"]\n",
    "            ,\"oob_score\":hyperopt_params[\"bootstrap\"] == True and hyperopt_params[\"oob_score\"] or False\n",
    "            ,\"random_state\":int(hyperopt_params[\"random_state\"])\n",
    "            # ,\"verbose\":int(hyperopt_params[\"verbose\"])\n",
    "            ,\"warm_start\":hyperopt_params[\"warm_start\"]\n",
    "            ,\"class_weight\":hyperopt_params[\"class_weight\"]\n",
    "            ,\"max_samples\":hyperopt_params[\"bootstrap\"] == True and hyperopt_params[\"max_samples\"] or None\n",
    "            ,'n_jobs':-1\n",
    "        }\n",
    "        # log(f\"本次参数:{params}\",LogLevel.INFO) \n",
    "        try:\n",
    "            if isinstance(self.Folds,(int,float)) and self.Folds > 0:\n",
    "                # print(self.Folds)\n",
    "                # self.StratifiedKFoldShuffle\n",
    "                strkf = StratifiedKFold(n_splits=self.Folds, shuffle=self.StratifiedKFoldShuffle)\n",
    "                '''\n",
    "                n_splits=6（默认5）：将数据集分成6个互斥子集，每次用5个子集数据作为训练集，1个子集为测试集，得到6个结果\n",
    "\n",
    "                shuffle=True（默认False）：每次划分前数据重新洗牌，每次的运行结果不同；shuffle=False：每次运行结果相同，相当于random_state=整数\n",
    "                random_state=1（默认None）：随机数设置为1，使得每次运行的结果一致\n",
    "                '''\n",
    "                # roc_aucs = np.zeros(self.Folds)\n",
    "                metrics_ = np.zeros(self.Folds)\n",
    "                log(f\"k={self.Folds}折分层交叉验证\",LogLevel.PASS)\n",
    "                for i,index_ in enumerate(strkf.split(self.x,self.y)):\n",
    "                    train_index,test_index = index_\n",
    "                    # print(train_index,test_index)\n",
    "                    X_train_KFold, X_test_KFold = self.x[train_index],self.x[test_index]\n",
    "                    y_train_KFold, y_test_KFold = self.y[train_index],self.y[test_index]\n",
    "                    gbdtc = RandomForestClassifier(**params)\n",
    "                    gbdtc = gbdtc.fit(X_train_KFold, y_train_KFold)\n",
    "                    gbdtc_proba = gbdtc.predict_proba(X_test_KFold)[:,1]\n",
    "                    gbdtc_pred = gbdtc.predict(X_test_KFold)\n",
    "                    \n",
    "                    if self.metrics_class == \"pr-auc\":\n",
    "                        metrics_[i] = self.PR_AUC(y_test_KFold, gbdtc_proba,gbdtc_pred)\n",
    "                    elif self.metrics_class == \"roc-auc\":\n",
    "                        metrics_[i] = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                    elif self.metrics_class == \"f1-score\":\n",
    "                        metrics_[i] = f1_score(y_test_KFold,gbdtc_pred) \n",
    "                    elif self.metrics_class == \"recall\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "                    elif self.metrics_class == \"precision\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"精确率|precision\"] \n",
    "                    elif self.metrics_class == \"accuracy\":\n",
    "                        metrics_[i] = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                    elif self.metrics_class == \"roc-auc-recall\":\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        recall = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        metrics_[i] = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[-1]\n",
    "                    elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        recall = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        accuracy = self.TPRN_Score(y_test_KFold,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                        metrics_[i] = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1] \n",
    "                    if self.metrics_class == \"all\":\n",
    "                        TPRN = self.TPRN_Score(y_test_KFold,gbdtc_pred)\n",
    "                        pr_auc = self.PR_AUC(y_test_KFold, gbdtc_proba,gbdtc_pred)\n",
    "                        roc_auc = self.ROC_AUC(y_test_KFold, gbdtc_proba)\n",
    "                        accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "                        precision = TPRN['精确率|precision']\n",
    "                        recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                        false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "                        miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "                        specificity = TPRN['特异度|specificity']\n",
    "                        f1score = f1_score(y_test_KFold,gbdtc_pred) \n",
    "                        \n",
    "                        metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,-false_alarm,-miss_rate,specificity,f1score])\n",
    "                        \n",
    "                        metrics_values = np.nan_to_num(metrics_values,0)\n",
    "                        if recall > self.min_recall:\n",
    "                            metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "                        else:\n",
    "                            metrics_weight = np.nan_to_num(self.metrics_weight,0)*self.cost_wight\n",
    "                        metrics_[i] = metrics_values.dot(metrics_weight)                    \n",
    "                # roc_auc  = roc_aucs.mean()\n",
    "                metrics_value = metrics_.mean()\n",
    "                    \n",
    "            else: \n",
    "                gbdtc = RandomForestClassifier(**params)\n",
    "                gbdtc =gbdtc.fit(self.x_train, self.y_train)\n",
    "                gbdtc_proba = gbdtc.predict_proba(self.x_val)[:,1]\n",
    "                gbdtc_pred = gbdtc.predict(self.x_val)\n",
    "                if self.metrics_class == \"pr-auc\":\n",
    "                    metrics_value = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "                elif self.metrics_class == \"roc-auc\":\n",
    "                    metrics_value = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                elif self.metrics_class == \"f1-score\":\n",
    "                    metrics_value = f1_score(self.y_val,gbdtc_pred)\n",
    "                elif self.metrics_class == \"recall\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "                elif self.metrics_class == \"precision\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"精确率|precision\"] \n",
    "                elif self.metrics_class == \"accuracy\":\n",
    "                    metrics_value = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                elif self.metrics_class == \"roc-auc-recall\":\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    metrics_value = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[-1]\n",
    "                elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    accuracy = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "                    metrics_value = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1]                      \n",
    "                elif self.metrics_class == \"all\":\n",
    "                    TPRN = self.TPRN_Score(self.y_val, gbdtc_pred)\n",
    "                    pr_auc = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "                    roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "                    accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "                    precision = TPRN['精确率|precision']\n",
    "                    recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "                    false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "                    miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "                    specificity = TPRN['特异度|specificity']\n",
    "                    f1score = f1_score(self.y_val,gbdtc_pred) \n",
    "                    metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,-false_alarm,-miss_rate,specificity,f1score])\n",
    "                    metrics_values = np.nan_to_num(metrics_values,0)\n",
    "                    if recall > self.min_recall:\n",
    "                        metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "                    else:\n",
    "                        metrics_weight = np.nan_to_num(self.metrics_weight,0)*self.cost_wight\n",
    "                    metrics_value = metrics_values.dot(metrics_weight)\n",
    "        except Exception as e:\n",
    "            log(str(e),LogLevel.ERROR)\n",
    "            metrics_value = self.historical_metrics.mean()   \n",
    "        # metrics_value = MyMetric.PR_AUC(self.y_val,gbdtc_proba,gbdtc_pred)\n",
    "        \n",
    "        func_end = time.time()\n",
    "        # global NOW_FUC_RUN_ITER\n",
    "        self.NOW_FUC_RUN_ITER += 1\n",
    "        self.historical_params.update({self.NOW_FUC_RUN_ITER-1:params})\n",
    "        self.historical_metrics[self.NOW_FUC_RUN_ITER-1] = metrics_value\n",
    "        \n",
    "#         log(f\"\"\"本次迭代{self.metrics_class}分数为:[{metrics_value}],\n",
    "#         用时:[{func_end-func_start}]秒,\n",
    "#         当前优化第:[{self.NOW_FUC_RUN_ITER}]次,\n",
    "#         已运行:[{self.NOW_FUC_RUN_ITER}]次，\n",
    "#         用时总计:[{datetime.timedelta(seconds=(func_end-self.Bayes_start_time))}]秒,\n",
    "#         \"\"\",LogLevel.PASS)\n",
    "        return -metrics_value\n",
    "    \n",
    "    def param_hyperopt(self,max_evals=100):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #保存迭代过程\n",
    "        trials = Trials()\n",
    "\n",
    "        #设置提前停止\n",
    "        ## 如果损失没有增加，将在 X 次迭代后停止的停止函数\n",
    "        early_stop_fn = no_progress_loss(self.EARLY_STOP_BAYES)\n",
    "\n",
    "        #定义代理模型\n",
    "        #algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)\n",
    "        # global hyperopt_params\n",
    "        # hyperopt_params = self.param_grid_hp\n",
    "        params_best = fmin(self.hyperopt_objective #目标函数\n",
    "                        , space = self.param_grid_hp #参数空间\n",
    "                        , algo = tpe.suggest #代理模型\n",
    "                        #, algo = algo\n",
    "                        , max_evals = max_evals #允许的迭代次数\n",
    "                        , verbose=True\n",
    "                        , trials = trials\n",
    "                        , early_stop_fn = early_stop_fn\n",
    "                        \n",
    "                        )\n",
    "\n",
    "        #打印最优参数，fmin会自动打印最佳分数\n",
    "        print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "            \"\\n\")\n",
    "        return params_best, trials\n",
    "    \n",
    "    def run(self):\n",
    "        t = 0\n",
    "        for params_name,obj in self.param_grid_hp.items():\n",
    "            t += 1\n",
    "            log(f\"已准备优化的第{t}个参数,名称:{params_name},类型:{obj}\",LogLevel.PASS)\n",
    "\n",
    "        self.Bayes_start_time = time.time()\n",
    "        self.NOW_FUC_RUN_ITER = 0\n",
    "        self.PARAMS_BEST, self.Trials = self.param_hyperopt(self.NUM_EVALS)\n",
    "        idx = np.argmin([-self.historical_metrics])\n",
    "        # self.historical_metrics[idx]\n",
    "        self.bayes_opt_parser = self.historical_params[idx]\n",
    "        log(f\"解析参数得到结果:{self.bayes_opt_parser}\",LogLevel.PASS)\n",
    "        \n",
    "    def test_params(self):\n",
    "        params = self.bayes_opt_parser\n",
    "        gbdtc = RandomForestClassifier(**params)\n",
    "        gbdtc =gbdtc.fit(self.x_train, self.y_train)\n",
    "        gbdtc_proba = gbdtc.predict_proba(self.x_val)[:,1]\n",
    "        gbdtc_pred = gbdtc.predict(self.x_val)\n",
    "        # metric = MyMetric.PR_AUC(self.y_val,gbdtc_proba,gbdtc_pred)\n",
    "        log(f'模型的评估报告1：\\n,{classification_report(self.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)\n",
    "        log(f'模型的评估报告2：\\n,{self.TPRN_Score(self.y_val, gbdtc_pred)}\\n',LogLevel.SUCCESS)\n",
    "        \n",
    "        # self.plot_roc(self.y_val, gbdtc_proba[:,1])\n",
    "        if self.metrics_class == \"pr-auc\":\n",
    "            metrics = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "        elif self.metrics_class == \"roc-auc\":\n",
    "            metrics = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "        elif self.metrics_class == \"f1-score\":\n",
    "            metrics = f1_score(self.y_val,gbdtc_pred)\n",
    "        elif self.metrics_class == \"recall\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"] \n",
    "        elif self.metrics_class == \"precision\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"精确率|precision\"] \n",
    "        elif self.metrics_class == \"accuracy\":\n",
    "            metrics = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "        elif self.metrics_class == \"roc-auc-recall\":\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            metrics = roc_auc*self.metrics_weight[0]*recall*self.metrics_weight[-1]\n",
    "        elif self.metrics_class == \"roc-auc-recall-accuracy\":\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            recall = self.TPRN_Score(self.y_val,gbdtc_pred)[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            accuracy = self.TPRN_Score(self.y_val,gbdtc_pred)[\"ACC正确率|accuracy\"]\n",
    "            metrics = roc_auc*self.metrics_weight[0]+recall*self.metrics_weight[1]+accuracy*self.metrics_weight[-1]                      \n",
    "        elif self.metrics_class == \"all\":\n",
    "            TPRN = self.TPRN_Score(self.y_val, gbdtc_pred)\n",
    "            pr_auc = self.PR_AUC(self.y_val, gbdtc_proba,gbdtc_pred)\n",
    "            roc_auc = self.ROC_AUC(self.y_val, gbdtc_proba)\n",
    "            accuracy = TPRN[\"ACC正确率|accuracy\"]\n",
    "            precision = TPRN['精确率|precision']\n",
    "            recall = TPRN[\"召回率|recall｜真阳率｜命中率\"]\n",
    "            false_alarm = TPRN['误报率|false alarm｜假阳率｜虚警率｜误检率'] \n",
    "            miss_rate = TPRN['漏报率|miss rate|也称为漏警率|漏检率']\n",
    "            specificity = TPRN['特异度|specificity']\n",
    "            f1score = f1_score(self.y_val,gbdtc_pred) \n",
    "            metrics_values = np.array([pr_auc,roc_auc,accuracy,precision,recall,false_alarm,miss_rate,specificity,f1score])\n",
    "            #metrics_weight = np.array(self.metrics_weight)\n",
    "            metrics_values = np.nan_to_num(metrics_values,0)\n",
    "            metrics_weight = np.nan_to_num(self.metrics_weight,0)\n",
    "            for metrice_name,metrics_value,weight in zip(self.all_metrice_names,metrics_values,metrics_weight):\n",
    "                log(f'测试{metrice_name}值为:{metrics_value},权重为{weight}',LogLevel.SUCCESS)\n",
    "            metrics = metrics_values.dot(metrics_weight) \n",
    "        log(f'测试优化参数的:【{self.metrics_class}】得分为:【{metrics}】,优化过程中的最高分为:【{self.historical_metrics.max()}】',LogLevel.SUCCESS)\n",
    "        return metrics\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    from sklearn import datasets\n",
    "    cancer=datasets.load_breast_cancer()\n",
    "    x=cancer.data\n",
    "    y=cancer.target\n",
    "\n",
    "    def Rollover(x):\n",
    "        x = x.astype(bool)\n",
    "        x = ~x\n",
    "        x = x.astype(int)\n",
    "        return x\n",
    "    ####TODO:将少数变成正例\n",
    "    y = Rollover(y)\n",
    "    boRF = BayesOptRF(x,y\n",
    "                       ,MAX_SHUFFLE=100\n",
    "                        ,Folds=0\n",
    "                        ,metrics_class=\"pr-auc\"\n",
    "                        #all=[1.pr_auc,2.roc_auc,3.accuracy,4.precision,5.recall,6.false_alarm,7.miss_rate,8.specificity,9.f1score]\n",
    "                        ,metrics_weight=[0,0.5,0.5,0,0,0,0,0,0]\n",
    "                        ,EARLY_STOP_BAYES=200\n",
    "                        ,NUM_EVALS=1000\n",
    "                        ,min_recall=0\n",
    "                        ,cost_wight=1\n",
    "                       )\n",
    "    boRF.run()\n",
    "    # boG.test_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ed85d6ea-f4dc-4f78-9c91-9de2b3766d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m2023-12-24 18:53:35.307463 - [SUCCESS] - 模型的评估报告1：\n",
      ",              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        71\n",
      "         1.0       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.307730 - [SUCCESS] - 模型的评估报告2：\n",
      ",{'混淆矩阵': matrix([[43,  0],\n",
      "        [ 0, 71]]), 'ACC正确率|accuracy': 1.0, '精确率|precision': 1.0, '召回率|recall｜真阳率｜命中率': 1.0, '误报率|false alarm｜假阳率｜虚警率｜误检率': 0.0, '漏报率|miss rate|也称为漏警率|漏检率': 0.0, '特异度|specificity': 1.0, 'F1-score:': 1.0, '真实正样本数': 43, '真实负样本数': 71}\n",
      "\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311417 - [SUCCESS] - 测试pr_auc值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311458 - [SUCCESS] - 测试roc_auc值为:1.0,权重为0.5\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311471 - [SUCCESS] - 测试accuracy值为:1.0,权重为0.5\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311480 - [SUCCESS] - 测试precision值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311489 - [SUCCESS] - 测试recall值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311497 - [SUCCESS] - 测试false_alarm值为:0.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311506 - [SUCCESS] - 测试miss_rate值为:0.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311514 - [SUCCESS] - 测试specificity值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311523 - [SUCCESS] - 测试f1score值为:1.0,权重为0.0\u001b[0m\n",
      "\u001b[0;36m2023-12-24 18:53:35.311544 - [SUCCESS] - 测试优化参数的:【all】得分为:【1.0】,优化过程中的最高分为:【1.0】\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boG.test_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c35d07db-4cc0-4816-82f8-0ff53b184d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641271038528311"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmin([-boRF.historical_metrics])\n",
    "boRF.historical_metrics[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b0fef4e6-411b-400e-860f-ccd919298679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 526,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 286,\n",
       " 'min_samples_split': 416,\n",
       " 'min_samples_leaf': 106,\n",
       " 'min_weight_fraction_leaf': 0.28522148572414313,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.14211011160987627,\n",
       " 'bootstrap': False,\n",
       " 'oob_score': False,\n",
       " 'random_state': 56,\n",
       " 'warm_start': False,\n",
       " 'class_weight': None,\n",
       " 'max_samples': None,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boRF.historical_params[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3d7c6a8-de5b-4d0f-bd1e-ebdb301b7269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688528970641475"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(**boRF.historical_params[idx])\n",
    "rfc = rfc.fit(train_x,train_y,)\n",
    "rfc_pred = rfc.predict(test_x)\n",
    "rfc_proba = rfc.predict_proba(test_x)[:,1]\n",
    "(ROC_AUC(test_y,rfc_proba)+sum(rfc_pred==test_y)/test_y.size)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d4eb2d1-6b42-4cb0-9077-a129633af2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871925558368324"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boRF.PR_AUC(test_y,rfc_proba,rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2e9285eb-ae89-4bb6-a52d-2a829d3d659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                | 265/600 [02:51<03:37,  1.54trial/s, best loss: -0.9990173599737964]\n",
      "\n",
      " \n",
      " best params:  {'alpha': 15.0, 'boosters': 1, 'colsample_bylevel': 0.6584435050605241, 'colsample_bynode': 0.0727297864386035, 'colsample_bytree': 0.9388869249397702, 'gamma': 0.0, 'grow_policy': 1, 'lambda': 23.0, 'learning_rate': 0.05930788431305209, 'max_bin': 517.0, 'max_delta_step': 57.0, 'max_depth': 90.0, 'max_leaves': 529.0, 'min_child_weight': 25.0, 'n_estimators': 814.0, 'num_parallel_tree': 71.0, 'refresh_leaf': 1, 'subsample': 0.7533073644285923, 'tree_method': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from OptMetrics import MyMetric\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from MyLogColor import log,LogLevel\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_curve,auc,f1_score,roc_curve,auc\n",
    "\n",
    "cancer=datasets.load_breast_cancer()\n",
    "x=cancer.data\n",
    "y=cancer.target\n",
    "\n",
    "def Rollover(x):\n",
    "    x = x.astype(bool)\n",
    "    x = ~x\n",
    "    x = x.astype(int)\n",
    "    return x\n",
    "####TODO:将少数变成正例\n",
    "y = Rollover(y)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "\n",
    "def ROC_AUC(test_y, proba):\n",
    "    fpr,tpr,threshold = roc_curve(test_y, proba)\n",
    "    roc_auc_ = auc(fpr,tpr)\n",
    "    return roc_auc_\n",
    "\n",
    "\n",
    "historical_metrics = []\n",
    "historical_params = {}\n",
    "\n",
    "boosters = ['gbtree','gblinear','dart']\n",
    "sampling_methods = ['uniform','gradient_based']\n",
    "tree_methods = [\"auto\",\"exact\",\"approx\",\"hist\"]\n",
    "refresh_leafs = [0,1]\n",
    "# process_types = [\"default\",\"update\"]#,\"refresh\",\"prune\"]\n",
    "grow_policys = [\"depthwise\",\"lossguide\"]\n",
    "# sample_types = [\"uniform\",\"weighted\"]\n",
    "normalize_types = [\"tree\",\"forest\"]\n",
    "rate_drops = []\n",
    "\n",
    "\n",
    "\n",
    "param_grid_hp = {\n",
    "    'boosters':hp.choice('boosters',boosters)\n",
    "    ,\"n_estimators\":hp.quniform(\"n_estimators\",50,1000,1)\n",
    "    ,\"learning_rate\":hp.uniform(\"learning_rate\",1e-5,1)\n",
    "    ,\"gamma\":hp.quniform(\"gamma\",0,100,1)\n",
    "    ,\"max_depth\":hp.quniform(\"max_depth\",6,200,1)\n",
    "    ,\"min_child_weight\":hp.quniform(\"min_child_weight\",0,100,1)\n",
    "    ,\"max_delta_step\":hp.quniform(\"max_delta_step\",0,100,1)\n",
    "    ,\"subsample\":hp.uniform(\"subsample\",0,1)\n",
    "    # ,\"sampling_method\":hp.choice(\"sampling_method\",sampling_methods)\n",
    "    ,\"colsample_bytree\":hp.uniform(\"colsample_bytree\",0,1)\n",
    "    ,\"colsample_bylevel\":hp.uniform(\"colsample_bylevel\",0,1)\n",
    "    ,\"colsample_bynode\":hp.uniform(\"colsample_bynode\",0,1)\n",
    "    ,\"lambda\":hp.quniform(\"lambda\",0,200,1)\n",
    "    ,\"alpha\":hp.quniform(\"alpha\",0,200,1)\n",
    "    ,\"tree_method\":hp.choice(\"tree_method\",tree_methods)\n",
    "    # ,\"scale_pos_weight\":hp.uniform(\"scale_pos_weight\",0,1000)\n",
    "    ,\"refresh_leaf\":hp.choice(\"refresh_leaf\",refresh_leafs)\n",
    "    # ,\"process_type\":hp.choice(\"process_type\",process_types)\n",
    "    ,\"grow_policy\":hp.choice(\"grow_policy\",grow_policys)\n",
    "    ,\"max_leaves\":hp.quniform(\"max_leaves\",0,10000,1)\n",
    "    ,\"max_bin\":hp.quniform(\"max_bin\",256,1000,1)\n",
    "    ,\"num_parallel_tree\":hp.quniform(\"num_parallel_tree\",1,100,1)   \n",
    "}\n",
    "# booster_dart_params = {\n",
    "#     \"sample_type\":hp.choice(\"sample_type\",sample_types)\n",
    "#     ,\"normalize_type\":hp.choice(\"normalize_type\",normalize_types)\n",
    "#     ,\"rate_drop\":hp.uniform(\"rate_drop\",0,1)\n",
    "#     ,\"one_drop\":hp.quniform(\"one_drop\",0,1000,1)\n",
    "#     ,\"skip_drop\":hp.uniform(\"skip_drop\",0,1)\n",
    "# }\n",
    "\n",
    "booster_gblinear_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "def PR_AUC(test_y,proba,pred):\n",
    "    precision,recall,_ = precision_recall_curve(test_y,proba)\n",
    "    f1 ,pr_auc = f1_score(test_y,pred),auc(recall,precision)\n",
    "    return pr_auc\n",
    "\n",
    "def hyperopt_objective(hyperopt_params): \n",
    "    params = {\n",
    "        \"objective\":\"binary:logistic\"\n",
    "        ,'boosters':hyperopt_params['boosters']\n",
    "        ,\"n_estimators\":int(hyperopt_params[\"n_estimators\"])\n",
    "        ,\"learning_rate\":hyperopt_params[\"learning_rate\"]\n",
    "        ,\"gamma\":hyperopt_params[\"gamma\"]\n",
    "        ,\"max_depth\":int(hyperopt_params[\"max_depth\"])\n",
    "        ,\"min_child_weight\":int(hyperopt_params[\"min_child_weight\"])\n",
    "        ,\"max_delta_step\":int(hyperopt_params[\"max_delta_step\"])\n",
    "        ,\"subsample\":hyperopt_params[\"subsample\"]\n",
    "        ,\"verbosity\":0\n",
    "        # ,\"sampling_method\":hyperopt_params[\"sampling_method\"]\n",
    "        ,\"colsample_bytree\":hyperopt_params[\"colsample_bytree\"]\n",
    "        ,\"colsample_bylevel\":hyperopt_params[\"colsample_bylevel\"]\n",
    "        ,\"colsample_bynode\":hyperopt_params[\"colsample_bynode\"]\n",
    "        ,\"lambda\":int(hyperopt_params[\"lambda\"])\n",
    "        ,\"alpha\":int(hyperopt_params[\"alpha\"])\n",
    "        ,\"tree_method\":hyperopt_params[\"tree_method\"]\n",
    "        ,\"scale_pos_weight\":(y_train==0).sum()/(y_train==1).sum()\n",
    "        ,\"refresh_leaf\":hyperopt_params[\"refresh_leaf\"]\n",
    "        # ,\"process_type\":hyperopt_params[\"process_type\"]\n",
    "        ,\"grow_policy\":hyperopt_params[\"grow_policy\"]\n",
    "        ,\"max_leaves\":int(hyperopt_params[\"max_leaves\"])\n",
    "        ,\"max_bin\":int(hyperopt_params[\"max_bin\"])\n",
    "        ,\"num_parallel_tree\":int(hyperopt_params[\"num_parallel_tree\"])   \n",
    "    }\n",
    "    # booster_dart_params = {\n",
    "    #     \"sample_type\":hyperopt_params[\"sample_type\"]\n",
    "    #     ,\"normalize_type\":hp.choice(\"normalize_type\",normalize_types)\n",
    "    #     ,\"rate_drop\":hyperopt_params[\"rate_drop\"]\n",
    "    #     ,\"one_drop\":int(hyperopt_params[\"one_drop\"])\n",
    "    #     ,\"skip_drop\":hyperopt_params[\"skip_drop\"]\n",
    "    # }\n",
    "    dtrain = xgb.DMatrix(x_train,label=y_train)\n",
    "    clf = xgb.train(params=params\n",
    "                   ,dtrain=dtrain\n",
    "                   ,num_boost_round=100\n",
    "                   ,evals=[(dtrain,\"train\")]\n",
    "                   ,verbose_eval=False # 不显示训练信息就改False\n",
    "                   # ,obj=logistic_obj\n",
    "                   )\n",
    "    dtest = xgb.DMatrix(x_val,label=y_val)\n",
    "    xgboost_proba = clf.predict(dtest)\n",
    "    # xgbosst_proba = np.nan_to_num(xgboost_proba,0)\n",
    "    \n",
    "    global NOW_FUC_RUN_ITER\n",
    "    NOW_FUC_RUN_ITER += 1\n",
    "    metric = ROC_AUC(y_val,xgboost_proba)\n",
    "    historical_metrics.append(metric)\n",
    "    historical_params.update({NOW_FUC_RUN_ITER-1:params})\n",
    "    return - metric\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "\n",
    "    #保存迭代过程\n",
    "    trials = Trials()\n",
    "\n",
    "    #设置提前停止\n",
    "    early_stop_fn = no_progress_loss(100)\n",
    "\n",
    "    #定义代理模型\n",
    "    #algo = partial(tpe.suggest, n_startup_jobs=20, n_EI_candidates=50)\n",
    "    params_best = fmin(hyperopt_objective #目标函数\n",
    "                       , space = param_grid_hp #参数空间\n",
    "                       , algo = tpe.suggest #代理模型\n",
    "                       #, algo = algo\n",
    "                       , max_evals = max_evals #允许的迭代次数\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "\n",
    "    #打印最优参数，fmin会自动打印最佳分数\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials\n",
    "\n",
    "NOW_FUC_RUN_ITER = 0\n",
    "PARAMS_BEST, Trials = param_hyperopt(600)\n",
    "\n",
    "historical_metrics = np.array(historical_metrics)\n",
    "idx = np.argmax(historical_metrics)\n",
    "params = historical_params[idx]\n",
    "dtrain = xgb.DMatrix(x_train,label=y_train)\n",
    "clf = xgb.train(params=params\n",
    "               ,dtrain=dtrain\n",
    "               ,num_boost_round=100\n",
    "               ,evals=[(dtrain,\"train\")]\n",
    "               ,verbose_eval=False # 不显示训练信息就改False\n",
    "               # ,obj=logistic_obj\n",
    "               )\n",
    "dtest = xgb.DMatrix(x_val,label=y_val)\n",
    "xgboost_proba = clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e462c042-0189-4b39-976c-6674445b0d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b0f3cc26-4c23-4c07-a653-278543f612cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3788a523-d641-447e-a900-f8d6d43462b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'boosters': 'gblinear',\n",
       " 'n_estimators': 814,\n",
       " 'learning_rate': 0.05930788431305209,\n",
       " 'gamma': 0.0,\n",
       " 'max_depth': 90,\n",
       " 'min_child_weight': 25,\n",
       " 'max_delta_step': 57,\n",
       " 'subsample': 0.7533073644285923,\n",
       " 'verbosity': 0,\n",
       " 'colsample_bytree': 0.9388869249397702,\n",
       " 'colsample_bylevel': 0.6584435050605241,\n",
       " 'colsample_bynode': 0.0727297864386035,\n",
       " 'lambda': 23,\n",
       " 'alpha': 15,\n",
       " 'tree_method': 'exact',\n",
       " 'scale_pos_weight': 1.6923076923076923,\n",
       " 'refresh_leaf': 1,\n",
       " 'grow_policy': 'lossguide',\n",
       " 'max_leaves': 529,\n",
       " 'max_bin': 517,\n",
       " 'num_parallel_tree': 71}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = historical_params[idx]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f05e4f-9312-4722-974b-d7e4ef9fb28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2fbc1944-bd0b-42a8-994b-731fe44e1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     \"objective\":\"binary:logistic\",  # 多分类的问题\n",
    "#     # 'num_class': 10,               # 类别数，与 multisoftmax 并用\n",
    "#     'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "#     'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "#     'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "#     'subsample': 0.7,              # 随机采样训练样本\n",
    "#     'colsample_bytree': 0.7,       # 生成树时进行的列采样\n",
    "#     'min_child_weight': 3,\n",
    "#     'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "#     'eta': 0.007,                  # 如同学习率\n",
    "#     'seed': 1000,\n",
    "#     'nthread': 4,                  # cpu 线程数\n",
    "# }\n",
    "dtrain = xgb.DMatrix(x_train,label=y_train)\n",
    "clf = xgb.train(params=params\n",
    "               ,dtrain=dtrain\n",
    "               ,num_boost_round=100\n",
    "               ,evals=[(dtrain,\"train\")]\n",
    "               ,verbose_eval=False # 不显示训练信息就改False\n",
    "               # ,obj=logistic_obj\n",
    "               )\n",
    "dtest = xgb.DMatrix(x_val,label=y_val)\n",
    "xgboost_proba = clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "46493c12-521b-4ee9-b1cc-afae5ec39b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgboost_proba>0.5).astype(int)==y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "69bbc297-bcce-4f46-86bd-47be803ecab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990173599737964"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC(y_val,xgboost_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4f710209-0ed8-4e6e-be8c-580b49620473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3361772 , 0.7981541 , 0.8203545 , 0.2562623 , 0.19996049,\n",
       "       0.86203134, 0.84072673, 0.7630306 , 0.49083444, 0.16953701,\n",
       "       0.18439867, 0.7572008 , 0.28317615, 0.78244716, 0.16682358,\n",
       "       0.81705254, 0.2380926 , 0.17154232, 0.18120608, 0.84068966,\n",
       "       0.41492915, 0.1975207 , 0.8623697 , 0.17965862, 0.2001096 ,\n",
       "       0.30956447, 0.21091042, 0.2258969 , 0.18100636, 0.8585446 ,\n",
       "       0.21630582, 0.15445712, 0.2917523 , 0.2086175 , 0.18125324,\n",
       "       0.18176576, 0.50360596, 0.24452032, 0.82379895, 0.33353013,\n",
       "       0.184684  , 0.80987316, 0.23368864, 0.17071378, 0.29894045,\n",
       "       0.24427083, 0.23724045, 0.22725883, 0.2851912 , 0.24281749,\n",
       "       0.7790351 , 0.8583394 , 0.38251728, 0.4090937 , 0.27092102,\n",
       "       0.16486017, 0.23074426, 0.8536615 , 0.57294697, 0.16257402,\n",
       "       0.16642316, 0.8546891 , 0.8358565 , 0.21942048, 0.17521901,\n",
       "       0.27275497, 0.8614003 , 0.861268  , 0.1881125 , 0.30207688,\n",
       "       0.7300041 , 0.8388176 , 0.17340842, 0.82658404, 0.20059933,\n",
       "       0.2836999 , 0.20356916, 0.5887914 , 0.15361242, 0.31868872,\n",
       "       0.8005318 , 0.15342234, 0.56907195, 0.84728295, 0.5475986 ,\n",
       "       0.8254069 , 0.5443915 , 0.8355164 , 0.3204446 , 0.18935606,\n",
       "       0.20400503, 0.37932557, 0.48287946, 0.17961966, 0.2143948 ,\n",
       "       0.21043184, 0.8199144 , 0.8024206 , 0.15749906, 0.8307012 ,\n",
       "       0.7339825 , 0.16245367, 0.82680255, 0.84920204, 0.27664933,\n",
       "       0.2326058 , 0.2355269 , 0.8203452 , 0.4998704 , 0.2826099 ,\n",
       "       0.79109854, 0.18117224, 0.41200194, 0.81395435], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cc3de-7269-465d-83d1-f9fcb7859ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoostAndScikitOPT_GPU",
   "language": "python",
   "name": "xgboostandscikitopt_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
