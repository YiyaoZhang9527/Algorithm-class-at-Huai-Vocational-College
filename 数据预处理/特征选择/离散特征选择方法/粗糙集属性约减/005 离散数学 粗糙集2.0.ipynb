{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "粗糙集是波兰理工大学Z.pawlak教授提出用来研究不完整数据，不精确知识的表达、学习，归纳等的一套理论\n",
    "\n",
    "它是一种新的处理模糊和不确定性问题的数学工具，已被广泛应用于知识发现、机器学习、决策支持、模式识别、专家系统及归纳推理等领域。\n",
    "\n",
    "粗糙集理论的特点是能够分析隐藏在数据中的事实，又不需要关于数据附加信息。\n",
    "\n",
    "其主要思想是在保持分类能力不变的前提下，通过知识约简，导出问题的决策或分类规则。\n",
    "\n",
    "从数学的角度看，粗糙集是研究集合的；从编程的角度看，粗糙集的研究对象是矩阵,只不过是一些特殊的矩阵；从人工智能的角度来看，粗糙集研究的是决策表。\n",
    "\n",
    "\n",
    "作者：思想永不平凡\n",
    "链接：https://www.jianshu.com/p/a129b7a6be9e\n",
    "来源：简书\n",
    "著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/Users/manmanzhang/Library/Mobile Documents/com~apple~CloudDocs/MyProject/InferenceSystem/src/I5_algorithm/im/未命名.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "        [\"病人\",\"头疼\",\"肌肉疼\",\"体温\",\"流感\"]\n",
    "        ,[\"e1\",'是', '是', '正常', '否']\n",
    "        ,[\"e2\",'是', '是', '高', '是']\n",
    "        ,[\"e3\",'是', '是', '很高', '是']\n",
    "        ,[\"e4\",'否', '是', '正常', '否']\n",
    "        ,[\"e5\",'否', '否', '高', '否']\n",
    "        ,[\"e6\",'否', '是', '很高', '是']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['病人', '头疼', '肌肉疼', '体温', '流感'],\n",
       "       ['e1', '是', '是', '正常', '否'],\n",
       "       ['e2', '是', '是', '高', '是'],\n",
       "       ['e3', '是', '是', '很高', '是'],\n",
       "       ['e4', '否', '是', '正常', '否'],\n",
       "       ['e5', '否', '否', '高', '否'],\n",
       "       ['e6', '否', '是', '很高', '是']], dtype='<U3')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決策屬性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['否', '是', '是', '否', '否', '是'], dtype='<U3')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decision_factor(info):\n",
    "    return info[1:,-1]\n",
    "decision_factor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'否': (3.0,\n",
       "  {'e1', 'e4', 'e5'},\n",
       "  array([ True, False, False,  True,  True, False])),\n",
       " '是': (3.0,\n",
       "  {'e2', 'e3', 'e6'},\n",
       "  array([False,  True,  True, False, False,  True]))}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_decision_factor(info):\n",
    "    dec_fac = decision_factor(info)\n",
    "    return {i:((dec_fac==i).dot(np.ones(dec_fac.shape[0])),set(info[1:,0][np.ravel(np.argwhere(dec_fac==i))]),dec_fac==i) for i in np.unique(dec_fac)}\n",
    "split_decision_factor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 论域\n",
    "### 第一列是“病人”，在这一列，除了第一行，还有六行，即有六个元素或者对象在信息系统中，这就是 U ，是非空有限对象集，称为论域。用集合表示为：\n",
    "# $$ U=\\{e_{1},e_{2},e_{3},e_{4},e_{5},e_{6}\\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universe_of_discourse(info):\n",
    "    return info[1:,:]\n",
    "\n",
    "    #{str(j[0]):i for i,j in zip(info[1:,1:],info[1:,:1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['e1', '是', '是', '正常', '否'],\n",
       "       ['e2', '是', '是', '高', '是'],\n",
       "       ['e3', '是', '是', '很高', '是'],\n",
       "       ['e4', '否', '是', '正常', '否'],\n",
       "       ['e5', '否', '否', '高', '否'],\n",
       "       ['e6', '否', '是', '很高', '是']], dtype='<U3')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe_of_discourse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 属性 $ (C_{i}) $\n",
    "### 那什么是属性呢，除了第一列之外的其他列都是属性了\n",
    "### 属性有条件属性和决策属性，决策属性为最后一列\n",
    "### 先介绍条件属性：$ (C_{i}) $\n",
    "### 设$(C_{1})$为头疼属性，为$(C_{2})$肌肉疼属性，为$(C_{3})$体温属性\n",
    "### 用集合表示为：\n",
    "\n",
    "### 头疼属性：\n",
    "# $ C_{1} = \\{是,是,是,否,否 \\} $  \n",
    "### 肌肉疼属性：\n",
    "# $ C_{2} = \\{是,是,是,否,是 \\} $ \n",
    "### 体温属性：\n",
    "# $ C_{3} = \\{正常,高,很高,正常,高,很高 \\} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_set(info):\n",
    "    return info[1:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def condition_attribute(info):\n",
    "    return info[1:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['是', '是', '正常'],\n",
       "       ['是', '是', '高'],\n",
       "       ['是', '是', '很高'],\n",
       "       ['否', '是', '正常'],\n",
       "       ['否', '否', '高'],\n",
       "       ['否', '是', '很高']], dtype='<U3')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_set(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流感(D)就是决策属性了\n",
    "# $ D=\\{ 否，是，是，否，否，是  \\} $\n",
    "可以看出，在信息系统中，有很多的对象，它们有着各种各样的属性\n",
    "\n",
    "其中不同的对象有着不同或者相同的条件属性，使得每个对象有着不同的特征，这些条件属性会影响到决策属性，决策属性不同，将决定着这个信息系统能被分成几类\n",
    "\n",
    "\n",
    "\n",
    "显然决策属性值的不同直接受条件属性的影响，可以说每一个条件属性都可能成为决定决策属性值的潜在影响因素。进而决定着信息系统中的对象会被划分到哪一类去\n",
    "\n",
    "但是，我们也知道，影响事物的潜在因素会有很多，有些会显著影响结果，有些会有一些影响，而有些因素却是可有可无的\n",
    "\n",
    "\n",
    "\n",
    "现在我们正处于大数据的时代，每个人每天的很多行为会产生各种各样的数据\n",
    "\n",
    "这些数据通常很大，维度很高，里面会有商家感兴趣的部分，但是数据维数太大了\n",
    "\n",
    "面对这种“数据极其丰富而信息相对缺乏”的情况，如何从海量的数据中获得有用的信息或者决定性因素会是我们很感兴趣的方面\n",
    "\n",
    "因此，面对这样一个含有大量信息的信息系统，如何去发掘出什么是影响决策属性值的关键属性是很有必要的\n",
    "\n",
    "而这些关键属性就隐藏在这一列列的条件属性中，有些属性对决策属性产生了重要的影响，而有些属性就显得可有可无了\n",
    "\n",
    "而我们就是希望能够找出这些对决策属性有着重要影响的条件属性\n",
    "\n",
    "\n",
    "\n",
    "对于上面的病例，有经验的医生可能一眼就看出来什么是影响一个病人患流感的关键因素\n",
    "\n",
    "而我们可能作为门外汉，可以学习通过一些粗糙集的知识，同样也能发掘出这样的关键因素！\n",
    "\n",
    "作者：思想永不平凡\n",
    "链接：https://www.jianshu.com/p/a129b7a6be9e\n",
    "来源：简书\n",
    "著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 等价类与等价关系\n",
    "\n",
    "在数学上，假设在一个集合上定义一个等价关系（用来表示），则中的某个元素的等价类就是中等价于的所有元素所形成的子集：\n",
    "# $$ [a]=\\{x\\in X|x \\sim a   \\} $$\n",
    "粗糙集中的等价类和等价关系\n",
    "\n",
    "$ S=(U,A=C\\cup D,V,f) $ 是决策信息系统，$ \\forall B\\subseteq C $ ，论域U的不可分辨关系被定义为：\n",
    "\n",
    "# $$ R_B=\\{(x,y)\\in U\\times U|f(x,a)=f(y,a),\\forall a\\in B   \\} $$\n",
    "很显然，不可分辨关系是一种等价关系。它将论域U划分为\n",
    "# $ U/R_{B},U/R_{B}=\\{E_{1},E_{2},...,E_{m} \\} $ \n",
    "是由等价关系 \n",
    "# $ R_{B} $ \n",
    "形成的等价类集合。由等价关系\n",
    "# $ R_{B} $ \n",
    "形成的等价类\n",
    "# $ [x]_{B}=\\{y|(x,y)\\in R_{B} \\} $\n",
    "是粗糙集理论中的基本知识粒。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设：\n",
    "## 论域\n",
    "## $ U=\\{e_{1},e_{2},e_{3},e_{4},e_{5},e_{6}  \\} $\n",
    "## 条件属性\n",
    "## $ c_{i}=\\{c_{1},c_{2},c_{3} \\} $\n",
    "## 决策属性\n",
    "## $ D=\\{d  \\} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['头疼', '肌肉疼'],\n",
       "       ['是', '是'],\n",
       "       ['是', '是'],\n",
       "       ['是', '是'],\n",
       "       ['否', '是'],\n",
       "       ['否', '否'],\n",
       "       ['否', '是']], dtype='<U3')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getX(info,*keyword):\n",
    "    return np.array([info[:,np.argwhere(info[0] == key)[0][0]] for key in np.array(keyword)]).T\n",
    "\n",
    "getX(data,\"头疼\",\"肌肉疼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求出等价商集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('e1',\n",
       "  'e2',\n",
       "  'e3'): array([['是', '是'],\n",
       "        ['是', '是'],\n",
       "        ['是', '是']], dtype='<U3'),\n",
       " ('e5',): array([['否', '否']], dtype='<U3'),\n",
       " ('e4',\n",
       "  'e6'): array([['否', '是'],\n",
       "        ['否', '是']], dtype='<U3')}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quotient_set(info,*keyword):\n",
    "    knowledge = getX(info,*keyword)\n",
    "    univ_disc = universe_of_discourse(knowledge)\n",
    "    print(f\"univ_disc{univ_disc}\")\n",
    "    e = info[1:,0]\n",
    "    result = {}\n",
    "    for keys in {tuple(i) for i  in univ_disc}:\n",
    "        _index = np.ravel(np.argwhere((univ_disc==np.array(keys)).dot(np.ones(len(keyword)))==len(keyword)))\n",
    "        e_index = e[_index]\n",
    "        result.update({tuple(e_index):univ_disc[_index]})\n",
    "    return result\n",
    "\n",
    "quotient_set(data,\"头疼\",\"肌肉疼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定关系查询等价类\n",
    " ：设R是A上的一个等价关系，与A中一个元素a相关的所有元素的集合被称做a的一个等价类[a]R.当仅考虑一个关系是时，可以省去下标，而简写成[a].形式地，\n",
    " $$ [a]R=｛s|(a,s)∈R｝$$\n",
    " .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U3')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equivalence_class(C,R,A):\n",
    "    column = np.ravel([np.argwhere(A[0]==c) for c in C])\n",
    "    change_U = A.T[column].T\n",
    "    univ_disc = universe_of_discourse(change_U)\n",
    "    Rm = len(R)\n",
    "    arr_one = np.ones(Rm)\n",
    "    e = A[1:,0]\n",
    "    return e[(univ_disc==R).dot(arr_one)==Rm]\n",
    "\n",
    "equivalence_class(C =[\"头疼\",\"肌肉疼\"],R=['是', '否'],A = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 列出所有知识粒度的等价关系对应\n",
    "$\\forall B\\subseteq C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "\n",
    "def combinationL(loop_val): # 多list组合函数\n",
    "    return np.array([i for i in product(*loop_val)])\n",
    "\n",
    "def drop_dim(List):\n",
    "    return [j for i in List for j in i]\n",
    "\n",
    "def comparefunc(A,B,bi,e,D,cname):\n",
    "    result = dict()\n",
    "    m,n = A.shape\n",
    "    t = -1\n",
    "    for a in A:\n",
    "        t+=1\n",
    "        for b in B:\n",
    "            bn = b.shape[0]\n",
    "            if bn < n:\n",
    "                for i in range(math.ceil(n/bn)):\n",
    "                    temp1 = (a[i:i+bn]==b).all()  \n",
    "                    if temp1:\n",
    "                        index_str = (e[t],i,i+bn)\n",
    "                        key = \"{}{}\".format(e[bi[t]],index_str)\n",
    "                        result1 = {key:{\"决策属性\":D[bi[t]],\"论域\":e[bi[t]],\"条件属性\":a,\"等价关系\":b,\"元素段坐标\":index_str}}    \n",
    "                        result.update(result1)\n",
    "            else:\n",
    "                temp2 = (a==b).all()\n",
    "                if temp2:\n",
    "                    index_str = (e[t],0,bn)\n",
    "                    key = \"{}{}\".format(e[bi[t]],index_str)\n",
    "                    result2 = {key:{\"决策属性\":D[bi[t]],\"论域\":e[bi[t]],\"条件属性\":a,\"等价关系\":b,\"元素段坐标\":index_str}}\n",
    "                    result.update(result2)\n",
    "    return result\n",
    "\n",
    "def creater_equivalence_relation(S,C):\n",
    "    cname = C\n",
    "    e = S[1:,0] # 论域\n",
    "    D = S[1:,-1] # 决策属性\n",
    "    Ddistion = set(D)\n",
    "    columns = np.ravel([np.argwhere(S[0]==c) for c in C]) #选择列\n",
    "    C = S.T[columns].T[1:] #选择的条件属性集\n",
    "    Cname = S.T[columns].T[0]\n",
    "    Cm ,Cn = C.shape\n",
    "    Dbool_index = {d:np.ravel(np.argwhere(D==d)) for d in Ddistion } # 决策属性分类\n",
    "    Cclass =[]\n",
    "    for ci,bi in Dbool_index.items():\n",
    "        Cb = C[bi]\n",
    "        cdistion = [set(Cb[:,c]) for c in range(len(Cb[0]))]\n",
    "        for i in range(len(cdistion)):\n",
    "            ccomb = combinationL(cdistion[:i+1])\n",
    "            temp_c = comparefunc(C[bi],ccomb,bi,e,D,cname)\n",
    "            Cclass.append(temp_c)\n",
    "    return Cclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1907640/4083884369.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  eq_  = np.array(List)[bool_func]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'否': {'论域': {0: array(['e4', 'e4', 'e4', 'e4'], dtype='<U2'),\n",
       "   1: array(['e1', 'e1', 'e1', 'e1'], dtype='<U2'),\n",
       "   2: array(['e5', 'e5', 'e5', 'e5'], dtype='<U2')},\n",
       "  '等价关系': {0: array([array(['否'], dtype='<U1'), array(['是'], dtype='<U1'),\n",
       "          array(['否', '是'], dtype='<U1'),\n",
       "          array(['否', '是', '正常'], dtype='<U2')], dtype=object),\n",
       "   1: array([array(['是'], dtype='<U1'), array(['是'], dtype='<U1'),\n",
       "          array(['是', '是'], dtype='<U1'),\n",
       "          array(['是', '是', '正常'], dtype='<U2')], dtype=object),\n",
       "   2: array([array(['否'], dtype='<U1'), array(['否'], dtype='<U1'),\n",
       "          array(['否', '否'], dtype='<U1'),\n",
       "          array(['否', '否', '高'], dtype='<U2')], dtype=object)},\n",
       "  '决策属性': {0: array(['否', '否', '否', '否'], dtype='<U1'),\n",
       "   1: array(['否', '否', '否', '否'], dtype='<U1'),\n",
       "   2: array(['否', '否', '否', '否'], dtype='<U1')},\n",
       "  '元素段坐标': {0: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object),\n",
       "   1: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object),\n",
       "   2: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object)}},\n",
       " '是': {'论域': {0: array(['e2', 'e2', 'e2', 'e2'], dtype='<U2'),\n",
       "   1: array(['e3', 'e3', 'e3', 'e3'], dtype='<U2'),\n",
       "   2: array(['e6', 'e6', 'e6', 'e6'], dtype='<U2')},\n",
       "  '等价关系': {0: array([array(['是'], dtype='<U1'), array(['是'], dtype='<U1'),\n",
       "          array(['是', '是'], dtype='<U1'),\n",
       "          array(['是', '是', '高'], dtype='<U2')], dtype=object),\n",
       "   1: array([array(['是'], dtype='<U1'), array(['是'], dtype='<U1'),\n",
       "          array(['是', '是'], dtype='<U1'),\n",
       "          array(['是', '是', '很高'], dtype='<U2')], dtype=object),\n",
       "   2: array([array(['否'], dtype='<U1'), array(['是'], dtype='<U1'),\n",
       "          array(['否', '是'], dtype='<U1'),\n",
       "          array(['否', '是', '很高'], dtype='<U2')], dtype=object)},\n",
       "  '决策属性': {0: array(['是', '是', '是', '是'], dtype='<U1'),\n",
       "   1: array(['是', '是', '是', '是'], dtype='<U1'),\n",
       "   2: array(['是', '是', '是', '是'], dtype='<U1')},\n",
       "  '元素段坐标': {0: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object),\n",
       "   1: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object),\n",
       "   2: array([list(['头疼']), list(['肌肉疼']), list(['头疼', '肌肉疼']),\n",
       "          list(['头疼', '肌肉疼', '体温'])], dtype=object)}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equivalence_relation(S,C,keyword=None):\n",
    "    D = S[1:,-1] # 决策属性\n",
    "    def filter_(ds):\n",
    "        result_e , result_R ,result_D ,result_location = [],[],[],[]\n",
    "        data = creater_equivalence_relation(ds,C)\n",
    "        for i in data:\n",
    "            for ik,iv in i.items():\n",
    "                e = iv['论域']\n",
    "                R = iv['等价关系']\n",
    "                D = iv['决策属性']\n",
    "                location = iv['元素段坐标']\n",
    "                result_e.append(e)\n",
    "                result_R.append(R)\n",
    "                result_D.append(D)\n",
    "                result_location.append(C[location[-2]:location[-1]])\n",
    "        def clear(List):\n",
    "            bool_func = np.array([np.ravel(np.argwhere(np.array(result_e) == coder)) for coder in set(result_e)])\n",
    "            eq_  = np.array(List)[bool_func]\n",
    "            return dict(enumerate(eq_))\n",
    "        return {'论域':clear(result_e),'等价关系':clear(result_R),'决策属性':clear(result_D),'元素段坐标':clear(result_location)}\n",
    "    if keyword == \"splitD\":\n",
    "        Ddistion = set(D)\n",
    "        DS = {d:filter_(np.vstack((S[0],S[1:][D==d]))) for d in Ddistion}\n",
    "        return DS\n",
    "    elif keyword == None:\n",
    "        return creater_equivalence_relation(S,C)\n",
    "equivalence_relation(data,[\"头疼\",\"肌肉疼\",'体温'],keyword=\"splitD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不可分辨关系\n",
    "相差不大的个体被归于同一类，它们的关系就是不可分辨关系。给定一个论域U和U上的一簇等价关系S，若P⊆S，且P≠∅，则∩P（P中所有等价关系的交集）仍然是论域U上的一个等价关系，称为P上的一个不可分辨关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definitionX(info,X,*keyword):\n",
    "    knowledge = getX(info,*keyword)\n",
    "    univ_disc = universe_of_discourse(knowledge)\n",
    "    data_dict = {i:j for i,j in zip(info[1:,0],univ_disc)}\n",
    "    return {X:np.array([data_dict[i] for i in X])} ,univ_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上/下近似/边界线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def Rouh_set_all(info,X,*keyword,change_approx = 'lower'):\n",
    "    quot_set = quotient_set(info,*keyword)\n",
    "    X ,knowledga = definitionX(info,X,*keyword)\n",
    "    intersect_list,index_list = [],[]\n",
    "    for set_ in quot_set:\n",
    "        intersect = (set(set_)&set(list(X)[0]))\n",
    "        lenght = len(intersect)    \n",
    "        if lenght > 0:\n",
    "            intersect_list.append(set_)\n",
    "            index_list.append(lenght)\n",
    "    if change_approx == 'lower':\n",
    "        return set(intersect_list[index_list.index(min(index_list))])\n",
    "    elif change_approx == \"upper\":\n",
    "        return {j for i in range(len(intersect_list)) for j in intersect_list[i]}\n",
    "    elif change_approx == \"boundary_region\":\n",
    "        upper = set([j for i in range(len(intersect_list)) for j in intersect_list[i]])\n",
    "        lower = set(list(intersect_list[index_list.index(min(index_list))]))\n",
    "        return upper-lower\n",
    "    elif change_approx==\"positive_field\":\n",
    "        return set(list(intersect_list[index_list.index(min(index_list))]))\n",
    "    elif change_approx == \"negative_field\":\n",
    "        univ_disc = set(info[1:,0])\n",
    "        return univ_disc-set(intersect_list[index_list.index(min(index_list))])\n",
    "    elif change_approx == \"R_exact_sets\":\n",
    "        temp = [list(combinations(intersect_list,i)) for i in range(1,len(intersect_list))]\n",
    "        exact = [e for e in drop_dim(temp) if set(len(e)==1 and e[0] or drop_dim(e))==set(X)]\n",
    "        lenght_set = len(exact)\n",
    "        return lenght_set > 0 and {\"R exact sets\":exact} or \"Rouh set\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "lower = {'e5'}\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "upper = {'e5', 'e2', 'e1', 'e3'}\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "boundary_region = {'e2', 'e1', 'e3'}\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "positive_field = {'e5'}\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "negative_field = {'e6', 'e4', 'e3', 'e2', 'e1'}\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "R_exact_sets = Rouh set\n"
     ]
    }
   ],
   "source": [
    "for i in ['lower',\"upper\",\"boundary_region\",\"positive_field\",\"negative_field\",\"R_exact_sets\"]:\n",
    "    print(i,\"=\",Rouh_set_all(data,(\"e2\",\"e3\",\"e5\"),\"头疼\",\"肌肉疼\",change_approx=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e5'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_approximation(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'lower')\n",
    "\n",
    "lower_approximation(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e1', 'e2', 'e3', 'e5'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upper_approximation(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'upper')\n",
    "upper_approximation(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 边界线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e1', 'e2', 'e3'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boundary_region(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'boundary_region')\n",
    "\n",
    "boundary_region(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e5'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def positive_field(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'positive_field')\n",
    "positive_field(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 负域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e1', 'e2', 'e3', 'e4', 'e6'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def negative_field(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'negative_field')\n",
    "negative_field(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精确集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this relationship has no R exact set'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def R_exact_sets(info,X,keyword):\n",
    "    test = Rouh_set_all(info,X,*keyword,change_approx = 'R_exact_sets')\n",
    "    return test != 'Rouh set' and test or \"this relationship has no R exact set\"\n",
    "R_exact_sets(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验给定X是否是论域的粗糙集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rouh_set(info,X,keyword):\n",
    "    return Rouh_set_all(info,X,*keyword,change_approx = 'R_exact_sets') == 'Rouh set'\n",
    "rouh_set(data,(\"e2\",\"e3\",\"e5\"),(\"头疼\",\"肌肉疼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 近似分类的:精度/粗糙度/质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n",
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n",
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n",
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n",
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n",
      "univ_disc[['是' '是' '正常']\n",
      " ['是' '是' '高']\n",
      " ['是' '是' '很高']\n",
      " ['否' '是' '正常']\n",
      " ['否' '否' '高']\n",
      " ['否' '是' '很高']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'近似分类精度': 0.3333333333333333,\n",
       " '粗糙度': 0.6666666666666667,\n",
       " '近似分类质量': 0.14285714285714285,\n",
       " '上近似': {'e2', 'e3', 'e6'},\n",
       " '下近似': {'e6'},\n",
       " '决策边界': {'e2', 'e3'},\n",
       " '正域': {'e6'},\n",
       " '负域': {'e1', 'e2', 'e3', 'e4', 'e5'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def approximate_classification(info,Uname,changeD):\n",
    "    U , n = info.shape\n",
    "    Dinfo = {d:np.vstack((info[0],info[1:][info[1:,-1]==d])) for d in set(info[1:,-1])}\n",
    "    new_info = Dinfo[changeD]\n",
    "    e = tuple(new_info[1:,0])\n",
    "    if rouh_set(info,e,Uname):\n",
    "        lowerR = lower_approximation(info,e,Uname)\n",
    "        pperR = upper_approximation(info,e,Uname)\n",
    "        boundaryR = boundary_region(info,e,Uname)\n",
    "        positiveR = positive_field(info,e,Uname)\n",
    "        negativeR = negative_field(info,e,Uname)\n",
    "        alphaR = len(lowerR)/len(pperR)\n",
    "        rhoR = 1- alphaR\n",
    "        gammaR = len(lowerR)/U\n",
    "        return {\"近似分类精度\":alphaR,\"粗糙度\":rhoR,\"近似分类质量\":gammaR,\"上近似\":pperR,\"下近似\":lowerR,\"决策边界\":boundaryR,\"正域\":positiveR,\"负域\":negativeR}\n",
    "    else:\n",
    "        test = Rouh_set_all(info,e,*Uname,change_approx = 'R_exact_sets')\n",
    "        return test\n",
    "approximate_classification(data,('头疼', '肌肉疼', '体温'),\"是\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识约简"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['否']\n",
      " ['否']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['是']\n",
      " ['否']\n",
      " ['是']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['正常']\n",
      " ['高']\n",
      " ['很高']\n",
      " ['正常']\n",
      " ['高']\n",
      " ['很高']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '是']\n",
      " ['是' '是']\n",
      " ['是' '是']\n",
      " ['否' '是']\n",
      " ['否' '否']\n",
      " ['否' '是']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['否' '正常']\n",
      " ['否' '高']\n",
      " ['否' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n",
      "univ_disc[['是' '正常']\n",
      " ['是' '高']\n",
      " ['是' '很高']\n",
      " ['是' '正常']\n",
      " ['否' '高']\n",
      " ['是' '很高']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('头疼',),\n",
       "  {'近似分类精度': 0.5,\n",
       "   '粗糙度': 0.5,\n",
       "   '近似分类质量': 0.42857142857142855,\n",
       "   '上近似': {'e1', 'e2', 'e3', 'e4', 'e5', 'e6'},\n",
       "   '下近似': {'e1', 'e2', 'e3'},\n",
       "   '决策边界': {'e4', 'e5', 'e6'},\n",
       "   '正域': {'e1', 'e2', 'e3'},\n",
       "   '负域': {'e4', 'e5', 'e6'}}],\n",
       " [('体温',),\n",
       "  {'近似分类精度': 0.5,\n",
       "   '粗糙度': 0.5,\n",
       "   '近似分类质量': 0.2857142857142857,\n",
       "   '上近似': {'e1', 'e2', 'e4', 'e5'},\n",
       "   '下近似': {'e2', 'e5'},\n",
       "   '决策边界': {'e1', 'e4'},\n",
       "   '正域': {'e2', 'e5'},\n",
       "   '负域': {'e1', 'e3', 'e4', 'e6'}}],\n",
       " [('肌肉疼',),\n",
       "  {'近似分类精度': 0.16666666666666666,\n",
       "   '粗糙度': 0.8333333333333334,\n",
       "   '近似分类质量': 0.14285714285714285,\n",
       "   '上近似': {'e1', 'e2', 'e3', 'e4', 'e5', 'e6'},\n",
       "   '下近似': {'e5'},\n",
       "   '决策边界': {'e1', 'e2', 'e3', 'e4', 'e6'},\n",
       "   '正域': {'e5'},\n",
       "   '负域': {'e1', 'e2', 'e3', 'e4', 'e6'}}],\n",
       " [('头疼', '肌肉疼'),\n",
       "  {'近似分类精度': 0.5,\n",
       "   '粗糙度': 0.5,\n",
       "   '近似分类质量': 0.42857142857142855,\n",
       "   '上近似': {'e1', 'e2', 'e3', 'e4', 'e5', 'e6'},\n",
       "   '下近似': {'e1', 'e2', 'e3'},\n",
       "   '决策边界': {'e4', 'e5', 'e6'},\n",
       "   '正域': {'e1', 'e2', 'e3'},\n",
       "   '负域': {'e4', 'e5', 'e6'}}],\n",
       " [('肌肉疼', '体温'),\n",
       "  {'近似分类精度': 0.3333333333333333,\n",
       "   '粗糙度': 0.6666666666666667,\n",
       "   '近似分类质量': 0.14285714285714285,\n",
       "   '上近似': {'e1', 'e4', 'e5'},\n",
       "   '下近似': {'e5'},\n",
       "   '决策边界': {'e1', 'e4'},\n",
       "   '正域': {'e5'},\n",
       "   '负域': {'e1', 'e2', 'e3', 'e4', 'e6'}}],\n",
       " [('头疼', '体温'),\n",
       "  {'近似分类精度': 0.3333333333333333,\n",
       "   '粗糙度': 0.6666666666666667,\n",
       "   '近似分类质量': 0.14285714285714285,\n",
       "   '上近似': {'e1', 'e4', 'e5'},\n",
       "   '下近似': {'e5'},\n",
       "   '决策边界': {'e1', 'e4'},\n",
       "   '正域': {'e5'},\n",
       "   '负域': {'e1', 'e2', 'e3', 'e4', 'e6'}}]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations,combinations\n",
    "\n",
    "def knowledge_reduction(info,changeD):\n",
    "    e = info[0][1:-1]\n",
    "    comb_e = drop_dim([list(combinations(e,i)) for i in range(1,len(e))])\n",
    "    appro_class = {comb:[comb,approximate_classification(data,comb,changeD)] for comb in comb_e}\n",
    "    str_appro_class = [str(e) for e in appro_class.values()]\n",
    "    distion_str_app  = set(str_appro_class)\n",
    "    counter = np.array([str_appro_class.count(i) for i in distion_str_app])\n",
    "    return [eval(tuple(distion_str_app)[i]) for i in np.ravel(np.argwhere(counter==counter.min()))]\n",
    "knowledge_reduction(data,\"否\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
