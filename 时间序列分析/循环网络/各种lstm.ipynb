{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a08ee73-12ad-44b6-b5bb-cff2018f48de",
   "metadata": {},
   "source": [
    "#### lstm 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16d6edd-25e8-41e1-8edf-e8183724a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangmanman/anaconda3/envs/NLP_lab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7134\n",
      "Epoch [2/100], Loss: 0.7111\n",
      "Epoch [3/100], Loss: 0.7088\n",
      "Epoch [4/100], Loss: 0.7067\n",
      "Epoch [5/100], Loss: 0.7046\n",
      "Epoch [6/100], Loss: 0.7025\n",
      "Epoch [7/100], Loss: 0.7005\n",
      "Epoch [8/100], Loss: 0.6986\n",
      "Epoch [9/100], Loss: 0.6967\n",
      "Epoch [10/100], Loss: 0.6947\n",
      "Epoch [11/100], Loss: 0.6928\n",
      "Epoch [12/100], Loss: 0.6910\n",
      "Epoch [13/100], Loss: 0.6891\n",
      "Epoch [14/100], Loss: 0.6872\n",
      "Epoch [15/100], Loss: 0.6852\n",
      "Epoch [16/100], Loss: 0.6833\n",
      "Epoch [17/100], Loss: 0.6813\n",
      "Epoch [18/100], Loss: 0.6794\n",
      "Epoch [19/100], Loss: 0.6773\n",
      "Epoch [20/100], Loss: 0.6753\n",
      "Epoch [21/100], Loss: 0.6733\n",
      "Epoch [22/100], Loss: 0.6712\n",
      "Epoch [23/100], Loss: 0.6691\n",
      "Epoch [24/100], Loss: 0.6670\n",
      "Epoch [25/100], Loss: 0.6649\n",
      "Epoch [26/100], Loss: 0.6628\n",
      "Epoch [27/100], Loss: 0.6607\n",
      "Epoch [28/100], Loss: 0.6587\n",
      "Epoch [29/100], Loss: 0.6567\n",
      "Epoch [30/100], Loss: 0.6547\n",
      "Epoch [31/100], Loss: 0.6528\n",
      "Epoch [32/100], Loss: 0.6510\n",
      "Epoch [33/100], Loss: 0.6492\n",
      "Epoch [34/100], Loss: 0.6474\n",
      "Epoch [35/100], Loss: 0.6457\n",
      "Epoch [36/100], Loss: 0.6439\n",
      "Epoch [37/100], Loss: 0.6420\n",
      "Epoch [38/100], Loss: 0.6400\n",
      "Epoch [39/100], Loss: 0.6378\n",
      "Epoch [40/100], Loss: 0.6354\n",
      "Epoch [41/100], Loss: 0.6327\n",
      "Epoch [42/100], Loss: 0.6298\n",
      "Epoch [43/100], Loss: 0.6267\n",
      "Epoch [44/100], Loss: 0.6235\n",
      "Epoch [45/100], Loss: 0.6201\n",
      "Epoch [46/100], Loss: 0.6166\n",
      "Epoch [47/100], Loss: 0.6130\n",
      "Epoch [48/100], Loss: 0.6094\n",
      "Epoch [49/100], Loss: 0.6057\n",
      "Epoch [50/100], Loss: 0.6019\n",
      "Epoch [51/100], Loss: 0.5981\n",
      "Epoch [52/100], Loss: 0.5943\n",
      "Epoch [53/100], Loss: 0.5904\n",
      "Epoch [54/100], Loss: 0.5866\n",
      "Epoch [55/100], Loss: 0.5827\n",
      "Epoch [56/100], Loss: 0.5788\n",
      "Epoch [57/100], Loss: 0.5750\n",
      "Epoch [58/100], Loss: 0.5712\n",
      "Epoch [59/100], Loss: 0.5675\n",
      "Epoch [60/100], Loss: 0.5638\n",
      "Epoch [61/100], Loss: 0.5601\n",
      "Epoch [62/100], Loss: 0.5565\n",
      "Epoch [63/100], Loss: 0.5528\n",
      "Epoch [64/100], Loss: 0.5491\n",
      "Epoch [65/100], Loss: 0.5454\n",
      "Epoch [66/100], Loss: 0.5416\n",
      "Epoch [67/100], Loss: 0.5377\n",
      "Epoch [68/100], Loss: 0.5337\n",
      "Epoch [69/100], Loss: 0.5296\n",
      "Epoch [70/100], Loss: 0.5254\n",
      "Epoch [71/100], Loss: 0.5210\n",
      "Epoch [72/100], Loss: 0.5165\n",
      "Epoch [73/100], Loss: 0.5118\n",
      "Epoch [74/100], Loss: 0.5071\n",
      "Epoch [75/100], Loss: 0.5022\n",
      "Epoch [76/100], Loss: 0.4971\n",
      "Epoch [77/100], Loss: 0.4920\n",
      "Epoch [78/100], Loss: 0.4868\n",
      "Epoch [79/100], Loss: 0.4814\n",
      "Epoch [80/100], Loss: 0.4759\n",
      "Epoch [81/100], Loss: 0.4702\n",
      "Epoch [82/100], Loss: 0.4644\n",
      "Epoch [83/100], Loss: 0.4583\n",
      "Epoch [84/100], Loss: 0.4521\n",
      "Epoch [85/100], Loss: 0.4456\n",
      "Epoch [86/100], Loss: 0.4389\n",
      "Epoch [87/100], Loss: 0.4320\n",
      "Epoch [88/100], Loss: 0.4248\n",
      "Epoch [89/100], Loss: 0.4174\n",
      "Epoch [90/100], Loss: 0.4097\n",
      "Epoch [91/100], Loss: 0.4018\n",
      "Epoch [92/100], Loss: 0.3935\n",
      "Epoch [93/100], Loss: 0.3850\n",
      "Epoch [94/100], Loss: 0.3760\n",
      "Epoch [95/100], Loss: 0.3667\n",
      "Epoch [96/100], Loss: 0.3570\n",
      "Epoch [97/100], Loss: 0.3469\n",
      "Epoch [98/100], Loss: 0.3364\n",
      "Epoch [99/100], Loss: 0.3256\n",
      "Epoch [100/100], Loss: 0.3146\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个LSTM模型\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态h0, c0为全0向量\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # 将输入x和隐藏状态(h0, c0)传入LSTM网络\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # 取最后一个时间步的输出作为LSTM网络的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 定义LSTM超参数\n",
    "input_size = 10   # 输入特征维度\n",
    "hidden_size = 32  # 隐藏单元数量\n",
    "num_layers = 2    # LSTM层数\n",
    "output_size = 2   # 输出类别数量\n",
    "\n",
    "# 构建一个随机输入x和对应标签y\n",
    "x = torch.randn(64, 5, 10)  # [batch_size, sequence_length, input_size]\n",
    "y = torch.randint(0, 2, (64,))  # 二分类任务，标签为0或1\n",
    "\n",
    "# 创建LSTM模型，并将输入x传入模型计算预测输出\n",
    "lstm = LSTM(input_size, hidden_size, num_layers, output_size)\n",
    "pred = lstm(x)  # [batch_size, output_size]\n",
    "\n",
    "# 定义损失函数和优化器，并进行模型训练\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 前向传播计算损失函数值\n",
    "    pred = lstm(x)  # 在每个epoch中重新计算预测输出\n",
    "    loss = criterion(pred.squeeze(), y)\n",
    "\n",
    "    # 反向传播更新模型参数\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 输出每个epoch的训练损失\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9894dc-9139-4218-aa2d-e818b47cc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((pred>0)[:,:1].T[0]),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ee43160-a164-4dbc-8a6c-6e6fc89c8c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.2742, 0.5629, 1.7146, 0.6699, 0.7747, 1.6594, 0.7094, 0.6375, 0.9172,\n",
       "        0.6195, 0.7075, 0.3255, 1.6340, 0.1935, 1.7029, 1.9187, 0.4304, 1.7519,\n",
       "        0.8964, 1.2886, 0.1921, 1.3157, 0.3414, 2.1218, 0.3145, 1.5517, 1.0473,\n",
       "        0.6802, 1.1804, 0.7574, 2.0330, 0.2840, 1.6806, 0.1962, 1.6692, 0.4877,\n",
       "        0.6007, 0.2638, 1.1992, 1.4083, 1.8598, 0.6409, 1.6314, 0.8195, 0.5100,\n",
       "        0.8480, 0.5383, 1.6253, 0.6145, 0.3386, 1.2286, 0.6351, 0.7723, 0.6185,\n",
       "        0.5660, 0.6822, 0.8704, 0.1046, 1.1036, 1.3511, 1.2697, 0.0896, 1.0423,\n",
       "        1.9787], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc09665d-62fc-4452-b3d6-6aa0a83d24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/938], Loss: 2.3088\n",
      "Epoch [1/10], Step [101/938], Loss: 0.7709\n",
      "Epoch [1/10], Step [201/938], Loss: 0.3712\n",
      "Epoch [1/10], Step [301/938], Loss: 0.2808\n",
      "Epoch [1/10], Step [401/938], Loss: 0.1265\n",
      "Epoch [1/10], Step [501/938], Loss: 0.1502\n",
      "Epoch [1/10], Step [601/938], Loss: 0.2009\n",
      "Epoch [1/10], Step [701/938], Loss: 0.0359\n",
      "Epoch [1/10], Step [801/938], Loss: 0.0661\n",
      "Epoch [1/10], Step [901/938], Loss: 0.0940\n",
      "Epoch [2/10], Step [1/938], Loss: 0.2269\n",
      "Epoch [2/10], Step [101/938], Loss: 0.0407\n",
      "Epoch [2/10], Step [201/938], Loss: 0.0941\n",
      "Epoch [2/10], Step [301/938], Loss: 0.1174\n",
      "Epoch [2/10], Step [401/938], Loss: 0.0797\n",
      "Epoch [2/10], Step [501/938], Loss: 0.1740\n",
      "Epoch [2/10], Step [601/938], Loss: 0.0220\n",
      "Epoch [2/10], Step [701/938], Loss: 0.0999\n",
      "Epoch [2/10], Step [801/938], Loss: 0.0529\n",
      "Epoch [2/10], Step [901/938], Loss: 0.1254\n",
      "Epoch [3/10], Step [1/938], Loss: 0.1738\n",
      "Epoch [3/10], Step [101/938], Loss: 0.0906\n",
      "Epoch [3/10], Step [201/938], Loss: 0.0648\n",
      "Epoch [3/10], Step [301/938], Loss: 0.1521\n",
      "Epoch [3/10], Step [401/938], Loss: 0.0253\n",
      "Epoch [3/10], Step [501/938], Loss: 0.0861\n",
      "Epoch [3/10], Step [601/938], Loss: 0.0301\n",
      "Epoch [3/10], Step [701/938], Loss: 0.2176\n",
      "Epoch [3/10], Step [801/938], Loss: 0.1253\n",
      "Epoch [3/10], Step [901/938], Loss: 0.1138\n",
      "Epoch [4/10], Step [1/938], Loss: 0.1078\n",
      "Epoch [4/10], Step [101/938], Loss: 0.0043\n",
      "Epoch [4/10], Step [201/938], Loss: 0.0281\n",
      "Epoch [4/10], Step [301/938], Loss: 0.0102\n",
      "Epoch [4/10], Step [401/938], Loss: 0.0814\n",
      "Epoch [4/10], Step [501/938], Loss: 0.0696\n",
      "Epoch [4/10], Step [601/938], Loss: 0.0537\n",
      "Epoch [4/10], Step [701/938], Loss: 0.0540\n",
      "Epoch [4/10], Step [801/938], Loss: 0.1775\n",
      "Epoch [4/10], Step [901/938], Loss: 0.0024\n",
      "Epoch [5/10], Step [1/938], Loss: 0.0723\n",
      "Epoch [5/10], Step [101/938], Loss: 0.0666\n",
      "Epoch [5/10], Step [201/938], Loss: 0.0316\n",
      "Epoch [5/10], Step [301/938], Loss: 0.0225\n",
      "Epoch [5/10], Step [401/938], Loss: 0.1116\n",
      "Epoch [5/10], Step [501/938], Loss: 0.1517\n",
      "Epoch [5/10], Step [601/938], Loss: 0.2175\n",
      "Epoch [5/10], Step [701/938], Loss: 0.0787\n",
      "Epoch [5/10], Step [801/938], Loss: 0.2709\n",
      "Epoch [5/10], Step [901/938], Loss: 0.0329\n",
      "Epoch [6/10], Step [1/938], Loss: 0.0552\n",
      "Epoch [6/10], Step [101/938], Loss: 0.0287\n",
      "Epoch [6/10], Step [201/938], Loss: 0.0397\n",
      "Epoch [6/10], Step [301/938], Loss: 0.0712\n",
      "Epoch [6/10], Step [401/938], Loss: 0.1286\n",
      "Epoch [6/10], Step [501/938], Loss: 0.0348\n",
      "Epoch [6/10], Step [601/938], Loss: 0.0918\n",
      "Epoch [6/10], Step [701/938], Loss: 0.2433\n",
      "Epoch [6/10], Step [801/938], Loss: 0.1377\n",
      "Epoch [6/10], Step [901/938], Loss: 0.0538\n",
      "Epoch [7/10], Step [1/938], Loss: 0.1211\n",
      "Epoch [7/10], Step [101/938], Loss: 0.1004\n",
      "Epoch [7/10], Step [201/938], Loss: 0.0032\n",
      "Epoch [7/10], Step [301/938], Loss: 0.0531\n",
      "Epoch [7/10], Step [401/938], Loss: 0.0397\n",
      "Epoch [7/10], Step [501/938], Loss: 0.0782\n",
      "Epoch [7/10], Step [601/938], Loss: 0.0165\n",
      "Epoch [7/10], Step [701/938], Loss: 0.0120\n",
      "Epoch [7/10], Step [801/938], Loss: 0.0759\n",
      "Epoch [7/10], Step [901/938], Loss: 0.0232\n",
      "Epoch [8/10], Step [1/938], Loss: 0.0493\n",
      "Epoch [8/10], Step [101/938], Loss: 0.0179\n",
      "Epoch [8/10], Step [201/938], Loss: 0.1326\n",
      "Epoch [8/10], Step [301/938], Loss: 0.0535\n",
      "Epoch [8/10], Step [401/938], Loss: 0.0056\n",
      "Epoch [8/10], Step [501/938], Loss: 0.1775\n",
      "Epoch [8/10], Step [601/938], Loss: 0.0079\n",
      "Epoch [8/10], Step [701/938], Loss: 0.0102\n",
      "Epoch [8/10], Step [801/938], Loss: 0.0792\n",
      "Epoch [8/10], Step [901/938], Loss: 0.0625\n",
      "Epoch [9/10], Step [1/938], Loss: 0.0639\n",
      "Epoch [9/10], Step [101/938], Loss: 0.1001\n",
      "Epoch [9/10], Step [201/938], Loss: 0.0211\n",
      "Epoch [9/10], Step [301/938], Loss: 0.0717\n",
      "Epoch [9/10], Step [401/938], Loss: 0.0066\n",
      "Epoch [9/10], Step [501/938], Loss: 0.0466\n",
      "Epoch [9/10], Step [601/938], Loss: 0.0280\n",
      "Epoch [9/10], Step [701/938], Loss: 0.0617\n",
      "Epoch [9/10], Step [801/938], Loss: 0.0228\n",
      "Epoch [9/10], Step [901/938], Loss: 0.0561\n",
      "Epoch [10/10], Step [1/938], Loss: 0.0399\n",
      "Epoch [10/10], Step [101/938], Loss: 0.0276\n",
      "Epoch [10/10], Step [201/938], Loss: 0.1341\n",
      "Epoch [10/10], Step [301/938], Loss: 0.1148\n",
      "Epoch [10/10], Step [401/938], Loss: 0.1940\n",
      "Epoch [10/10], Step [501/938], Loss: 0.0398\n",
      "Epoch [10/10], Step [601/938], Loss: 0.0281\n",
      "Epoch [10/10], Step [701/938], Loss: 0.0139\n",
      "Epoch [10/10], Step [801/938], Loss: 0.0055\n",
      "Epoch [10/10], Step [901/938], Loss: 0.0729\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Hyper Parameters\n",
    "epochs = 10           # 训练整批数据多少次, 为了节约时间, 我们只训练一次\n",
    "batch_size = 64\n",
    "time_step = 28      # rnn 时间步数 / 图片高度\n",
    "input_size = 28     # rnn 每步输入值 / 图片每行像素\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "lr = 0.01           # learning rate\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Mnist手写数字\n",
    "train_data = dsets.MNIST(root='./mnist/',    # 保存或者提取位置\n",
    "                         train=True,  # this is tra`ining data\n",
    "                         transform=transforms.ToTensor(),    # 转换 PIL.Image or numpy.ndarray 成\n",
    "                                                    # torch.FloatTensor (C x H x W), 训练的时候 normalize 成 [0.0, 1.0] 区间\n",
    "                         download=True,          # 没下载就下载, 下载了就不用再下了改成False\n",
    ")\n",
    "\n",
    "test_data = dsets.MNIST(root='./mnist/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor())\n",
    "# batch_size = 64\n",
    "# Dataloader\n",
    "# PyTorch中数据读取的一个重要接口，该接口定义在dataloader.py中，只要是用PyTorch来训练模型基本都会用到该接口（除非用户重写…），\n",
    "# 该接口的目的：将自定义的Dataset根据batch size大小、是否shuffle等封装成一个Batch Size大小的Tensor，用于后面的训练。\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True) # 在每个epoch开始的时候，对数据重新打乱进行训练。在这里其实没啥用，因为只训练了一次\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "# LSTM\n",
    "# __init__ is basically a function which will \"initialize\"/\"activate\" the properties of the class for a specific object\n",
    "# self represents that object which will inherit those properties\n",
    "class simpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(simpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # 初始化隐藏状态h0, c0为全0向量\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "#         # 将输入x和隐藏状态(h0, c0)传入LSTM网络\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "#         # 取最后一个时间步的输出作为LSTM网络的输出\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        # 初始化hidden和memory cell参数\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, (h_n, h_c) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 选取最后一个时刻的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = simpleLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# train the model\n",
    "# 关于reshape(-1)的解释 https://www.zhihu.com/question/52684594\n",
    "# view()和reshape()区别的解释 https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch\n",
    "\n",
    "\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, time_step, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1adcb9-6ee0-40b1-8b50-3f3bd0625fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df242216-a607-4cd1-b35e-b4b8dcfc2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.05 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.reshape(-1, time_step, input_size).to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2563f787-f508-4f48-ab38-061fa5c76d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.05 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# https://stackoverflow.com/questions/55627780/evaluating-pytorch-models-with-torch-no-grad-vs-model-eval\n",
    "# torch.max()用法。https://blog.csdn.net/weixin_43255962/article/details/84402586\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, time_step, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26330761-45a5-4350-b0a1-be4949b005d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785901b3-be78-40f9-8da9-215624238be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6a1f2-40f4-40d3-b323-f0852594552a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP_lab]",
   "language": "python",
   "name": "conda-env-NLP_lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
